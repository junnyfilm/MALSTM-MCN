{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f799a1-ddfc-4159-8de8-165d7f76bf0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from numpy import inf\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import pickle\n",
    "import argparse, sys, os\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "import torchvision.transforms.functional as Fv\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchsummary import summary\n",
    "from torch.optim import lr_scheduler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch import topk\n",
    "from tqdm.notebook import tqdm # 프로세스 바\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "# device = torch.device(\"cuda:%d\" % 0 if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "# from dataloader_hilbert_att import DataLoader\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa5bce8-557e-4dba-8703-15f4950d9d27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gt_1500_10.npy', 'gt_2700_25.npy', 'testset', 'x_1500_10.npy', 'x_2700_25.npy', 'y_1500_10.npy', 'y_2700_25.npy', 'z_1500_10.npy', 'z_2700_25.npy']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"../data\"\n",
    "file_list = os.listdir(path)\n",
    "print(file_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13e2224-6996-4ef0-931c-caed717e134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_1500_10=np.load(\"../data/\"+file_list[0])\n",
    "x_1500_10=np.load(\"../data/\"+file_list[3])\n",
    "y_1500_10=np.load(\"../data/\"+file_list[5])\n",
    "z_1500_10=np.load(\"../data/\"+file_list[7])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e2a6573-2030-42bc-b7e0-8fce90638b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(x): # RMS 함수 정의\n",
    "    return np.sqrt(np.mean(x**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4499f73-3768-446c-a484-ed6c0678d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1500=np.concatenate((np.expand_dims(x_1500_10, axis=1),np.expand_dims(y_1500_10, axis=1),np.expand_dims(z_1500_10, axis=1)),axis=1)\n",
    "label_1500=gt_1500_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "799adbe9-8921-4eb5-9caa-3553c09b9660",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "label=[]\n",
    "for i in range(len(data_1500)):\n",
    "    if label_1500[i]==1:\n",
    "        if rms(data_1500[i][0])>0.05:\n",
    "            data.append(data_1500[i])\n",
    "            label.append(0)\n",
    "    if label_1500[i]==2:\n",
    "        if rms(data_1500[i][0])>0.05:\n",
    "            data.append(data_1500[i])\n",
    "            label.append(1)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "137d5cc9-8232-48cf-b316-7623597b33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(data)\n",
    "label=np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d97466a-5ea7-41c5-9ad5-ee1509d75ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19283, 3, 200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cad946e-c35f-4762-9647-dc6488cc4352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#depthwise version\n",
    "class customdataset(Dataset):\n",
    "    def __init__(self, data, label): \n",
    "        super().__init__()\n",
    "        self.data=torch.tensor(data)\n",
    "        self.label=torch.tensor(label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        label = self.label[idx] \n",
    "                \n",
    "        return  x.to(device).float(), label.to(device).long()\n",
    "train_set, valid_set, train_label, valid_label = train_test_split(data, label, train_size=0.8, random_state=1)\n",
    "traindataset = customdataset(train_set, train_label)\n",
    "validdataset = customdataset(valid_set, valid_label)\n",
    "\n",
    "traindataloader = DataLoader(traindataset, batch_size=32, shuffle=True, drop_last=True )\n",
    "validdataloader = DataLoader(validdataset, batch_size=32, shuffle=True, drop_last=True )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0362a2-2f3d-42c2-8c09-96687d968f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b948a8e-b122-4caa-91dc-842371493351",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aba12c97-d094-4b34-8ce0-bef8fb306463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dilated_Module(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Dilated_Module,self).__init__()\n",
    "        self.conv1=nn.Conv1d(in_channels, int(out_channels/4), kernel_size = 5, stride = 1, padding = ((5)//2), dilation=1, bias=False)        \n",
    "        self.conv2=nn.Conv1d(in_channels, int(out_channels/4), kernel_size = 5, stride = 1, padding = ((5+4*2)//2), dilation=3, bias=False)        \n",
    "        self.conv3=nn.Conv1d(in_channels, int(out_channels/4), kernel_size = 5, stride = 1, padding = ((5+4*4)//2), dilation=5, bias=False)\n",
    "        self.conv4=nn.Conv1d(in_channels, int(out_channels/4), kernel_size = 5, stride = 1, padding = ((5+4*6)//2), dilation=7, bias=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        ''' input x should be in size [B,F,T], where \n",
    "            B = Batch size\n",
    "            F = features\n",
    "            T = Time samples\n",
    "        '''\n",
    "        x1=self.conv1(x)\n",
    "        x2=self.conv2(x)\n",
    "        x3=self.conv3(x)\n",
    "        x4=self.conv4(x)\n",
    "        \n",
    "        y=torch.cat([x1,x2,x3,x4],dim=1)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "205cce2d-5428-4fd1-8936-34f0b2e71e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLSTMfcn_MSN(nn.Module):\n",
    "    def __init__(self, *, num_classes, num_features,\n",
    "                 num_lstm_out, num_lstm_layers=1, \n",
    "                 conv1_nf=128, conv2_nf=256, conv3_nf=128,\n",
    "                 lstm_drop_p=0.8, fc_drop_p=0.3):\n",
    "        super(MLSTMfcn_MSN, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.num_lstm_out = num_lstm_out\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "\n",
    "        \n",
    "        self.conv1_nf = conv1_nf\n",
    "        self.conv2_nf = conv2_nf\n",
    "        self.conv3_nf = conv3_nf\n",
    "\n",
    "        self.dilated_1=Dilated_Module(self.num_features, self.conv1_nf)\n",
    "        self.dilated_2=Dilated_Module(self.conv1_nf, self.conv2_nf)\n",
    "        self.dilated_3=Dilated_Module(self.conv2_nf, self.conv3_nf)\n",
    "\n",
    "        self.lstm_drop_p = lstm_drop_p\n",
    "        self.fc_drop_p = fc_drop_p\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.num_features, \n",
    "                            hidden_size=self.num_lstm_out,\n",
    "                            num_layers=self.num_lstm_layers,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(self.conv1_nf)\n",
    "        self.bn2 = nn.BatchNorm1d(self.conv2_nf)\n",
    "        self.bn3 = nn.BatchNorm1d(self.conv3_nf)\n",
    "\n",
    "        self.se1 = SELayer(self.conv1_nf)  # ex 128\n",
    "        self.se2 = SELayer(self.conv2_nf)  # ex 256\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstmDrop = nn.Dropout(self.lstm_drop_p)\n",
    "        self.convDrop = nn.Dropout(self.fc_drop_p)\n",
    "\n",
    "        self.fc = nn.Linear(self.conv3_nf+self.num_lstm_out, self.num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ''' input x should be in size [B,T,F], where \n",
    "            B = Batch size\n",
    "            T = Time samples\n",
    "            F = features\n",
    "        '''\n",
    "        x=x.transpose(2,1)\n",
    "        ''' input x should be in size [B,T,F], where \n",
    "            B = Batch size\n",
    "            T = Time samples\n",
    "            F = features\n",
    "        '''       \n",
    "        # x1 = nn.utils.rnn.pack_padded_sequence(x, seq_lens, \n",
    "        #                                        batch_first=True, \n",
    "        #                                        enforce_sorted=False)\n",
    "        x1, (ht,ct) = self.lstm(x)\n",
    "        x1 = self.lstmDrop(x1)\n",
    "        # x1, _ = nn.utils.rnn.pad_packed_sequence(x1, batch_first=True, \n",
    "        #                                          padding_value=0.0)\n",
    "        # print(x1.size())\n",
    "        x1 = x1[:,-1,:]\n",
    "        \n",
    "        x2 = x.transpose(2,1)\n",
    "        x2 = self.convDrop(self.relu(self.bn1(self.dilated_1(x2))))\n",
    "        # print(x2.size())\n",
    "        x2 = self.se1(x2)\n",
    "        x2 = self.convDrop(self.relu(self.bn2(self.dilated_2(x2))))\n",
    "        # print(x2.size())\n",
    "        x2 = self.se2(x2)\n",
    "        x2 = self.convDrop(self.relu(self.bn3(self.dilated_3(x2))))\n",
    "        # print(x2.size())\n",
    "        x2 = torch.mean(x2,2)\n",
    "        \n",
    "        x_all = torch.cat((x1,x2),dim=1)\n",
    "        x_out = self.fc(x_all)\n",
    "        x_out = F.log_softmax(x_out, dim=1)\n",
    "\n",
    "        return x_out,x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19f084af-b60b-456d-ac62-003e1a66ae4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation(model, testloader, criterion):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for inputs, labels in testloader:\n",
    "        inputs = inputs.float()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        output,_ = model.forward(inputs)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ## Calculating the accuracy \n",
    "        # Model's output is log-softmax, take exponential to get the probabilities\n",
    "        ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38fb20bd-796d-472a-8240-8ebeb323666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(classifier, dataloader,PATH):\n",
    "    # setup the network\n",
    "    predlist=[]\n",
    "    real=[]    \n",
    "    classifier.load_state_dict(PATH)\n",
    "\n",
    "    classifier.eval()\n",
    "    correct = 0.0\n",
    "    \n",
    "    max_tr_score = 0\n",
    "    max_val_score = 0\n",
    "    for batch_idx, (data) in enumerate(dataloader):\n",
    "    \n",
    "        signal1,label = data\n",
    "        signal1,label = Variable(signal1.cuda()),Variable(label.cuda().long())\n",
    "        out,_ = classifier(signal1)   \n",
    "\n",
    "        pred = out.data.max(1, keepdim= True)[1]\n",
    "        predlist.append(pred.cpu().detach().numpy().squeeze())\n",
    "        real.append(label)        \n",
    "        correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        # predlist.append(pred)\n",
    "    print('\\nAccuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        correct, len(dataloader.dataset), 100. * float(correct) / len(dataloader.dataset)))\n",
    "    acc=100. * float(correct) / len(dataloader.dataset)\n",
    "    return acc,predlist,real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f04f53c8-aaaf-4374-a433-9385c7eb8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "def confusionmatrix(y_pred1, y_test1, column=['class0','class1','class2','class3','class4']):\n",
    "    # y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    # _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    a=[]\n",
    "    b=[]\n",
    "    for i in range(len(y_test1)):\n",
    "        a.append(y_test1[i].detach().cpu().item())\n",
    "        b.append(y_pred1[i].item())\n",
    "    y_test=a\n",
    "    y_pred=b\n",
    "    df_cm = pd.DataFrame(confusion_matrix(y_test,y_pred))\n",
    "    df_cm.index=column\n",
    "    df_cm.columns=column\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    b, t = plt.ylim() \n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t)\n",
    "    \n",
    "\n",
    "    df_cm =df_cm / df_cm.astype(np.float).sum(axis=1)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    b, t = plt.ylim() \n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t)\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47aaa326-76b3-4b40-a602-defa1a7e70bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.0005, 0.0001],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'hidden_size': [8, 64, 128],\n",
    "    'optimizer': ['Adam', 'RMSprop', 'SGD']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60f5daac-e958-4670-9f83-c86f5e8a14bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(modelname,train_loader, valid_loader):\n",
    "\n",
    "\n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "    criterion = nn.NLLLoss().to(device)\n",
    "    epochs=500\n",
    "    print_every=1000\n",
    "\n",
    "    # 0.001 32 8 Adam\n",
    "    lr = param_grid['lr'][0]\n",
    "    batch_size = param_grid['batch_size'][0]\n",
    "    num_lstm_out = param_grid['hidden_size'][0]\n",
    "    optimizer_name = param_grid['optimizer'][0]\n",
    "\n",
    "    model =modelname.to(device)\n",
    "\n",
    "\n",
    "    # 옵티마이저 설정\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "    #train\n",
    "    steps = 0\n",
    "\n",
    "    for e in tqdm(range(epochs)):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            steps += 1\n",
    "\n",
    "            inputs = inputs.float()\n",
    "            inputs, labels = inputs.to(device),labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # print(inputs.shape)\n",
    "            # print(model.forward(inputs).shape)\n",
    "            output,_ = model.forward(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                model.eval()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    valid_loss, accuracy = validation(model, valid_loader, criterion)\n",
    "\n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.6f}.. \".format(train_loss/print_every),\n",
    "                      \"Val Loss: {:.6f}.. \".format(valid_loss/len(valid_loader)),\n",
    "                      \"Val Accuracy: {:.2f}%\".format(accuracy/len(valid_loader)*100))\n",
    "\n",
    "                # save model if validation loss has decreased\n",
    "                if valid_loss <= valid_loss_min:\n",
    "                    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                    valid_loss_min,\n",
    "                    valid_loss))\n",
    "                    torch.save(model.state_dict(),  './malstm_msn_cv_cond_1_esb_1_2.pt')\n",
    "                    valid_loss_min = valid_loss\n",
    "                    bestmodel=model\n",
    "\n",
    "                train_loss = 0\n",
    "\n",
    "                model.train()\n",
    "    return bestmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4525ed6c-7e68-4b46-abb9-11a418c1eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fail_index(pred, real, cross_val_num):\n",
    "    failed=[]\n",
    "    with open('test_fold_index_1.pickle', 'rb') as f:\n",
    "        test_fold_index = pickle.load(f)\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        if pred[i].item()!=real[i].detach().cpu().item():\n",
    "            failed.append(test_fold_index[cross_val_num-1][i])\n",
    "    \n",
    "    return failed\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd038e19-ce5e-4342-ae51-c213d775865f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe26e4eb-50b6-4c08-a71e-0075e45b5b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69177374-b3fc-4a2b-86cb-5c06e9af2440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.0005, 0.0001],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'hidden_size': [8, 64, 128],\n",
    "    'optimizer': ['Adam', 'RMSprop', 'SGD']\n",
    "}\n",
    "lr = param_grid['lr'][0]\n",
    "batch_size = param_grid['batch_size'][0]\n",
    "num_lstm_out = param_grid['hidden_size'][0]\n",
    "optimizer_name = param_grid['optimizer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a8b022a-e288-4d1e-8d46-4bd5b6ddc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(classifier, dataloader):\n",
    "    # setup the network\n",
    "    predlist=[]\n",
    "    real=[]    \n",
    "\n",
    "    classifier.eval()\n",
    "    correct = 0.0\n",
    "    \n",
    "    max_tr_score = 0\n",
    "    max_val_score = 0\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "    \n",
    "        signal1 = data\n",
    "        signal1 = Variable(signal1.cuda())\n",
    "        \n",
    "        \n",
    "        out1,_ = classifier(signal1)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        pred = out1.data.max(1, keepdim= True)[1]\n",
    "        predlist.append(pred.cpu().detach().numpy().squeeze())\n",
    "\n",
    "    \n",
    "    return predlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14852821-dd6e-4aa4-9c1f-8e5025c2fd53",
   "metadata": {},
   "source": [
    "## cross val 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1d2ef27-d07e-4f7a-a8cf-1bbbf2c6c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelll = MLSTMfcn_MSN(num_classes=2, \n",
    "                           num_features=3,\n",
    "                           num_lstm_out=num_lstm_out).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ed1622d-f48c-4b01-b84e-b40348203b52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd530f718475492bb8ee18d05fd5b23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/500..  Training Loss: 0.002567..  Val Loss: 2.957819..  Val Accuracy: 51.93%\n",
      "Validation loss decreased (inf --> 354.938246).  Saving model ...\n",
      "Epoch: 5/500..  Training Loss: 0.003709..  Val Loss: 0.127510..  Val Accuracy: 94.56%\n",
      "Validation loss decreased (354.938246 --> 15.301234).  Saving model ...\n",
      "Epoch: 7/500..  Training Loss: 0.003058..  Val Loss: 6.544856..  Val Accuracy: 51.41%\n",
      "Epoch: 9/500..  Training Loss: 0.003865..  Val Loss: 0.068629..  Val Accuracy: 97.29%\n",
      "Validation loss decreased (15.301234 --> 8.235427).  Saving model ...\n",
      "Epoch: 11/500..  Training Loss: 0.003406..  Val Loss: 0.959841..  Val Accuracy: 75.10%\n",
      "Epoch: 13/500..  Training Loss: 0.005751..  Val Loss: 0.068804..  Val Accuracy: 97.06%\n",
      "Epoch: 15/500..  Training Loss: 0.003437..  Val Loss: 0.070907..  Val Accuracy: 97.29%\n",
      "Epoch: 17/500..  Training Loss: 0.003478..  Val Loss: 0.126400..  Val Accuracy: 95.44%\n",
      "Epoch: 19/500..  Training Loss: 0.005466..  Val Loss: 0.056984..  Val Accuracy: 97.66%\n",
      "Validation loss decreased (8.235427 --> 6.838026).  Saving model ...\n",
      "Epoch: 21/500..  Training Loss: 0.004660..  Val Loss: 3.338628..  Val Accuracy: 55.29%\n",
      "Epoch: 23/500..  Training Loss: 0.005911..  Val Loss: 0.009437..  Val Accuracy: 99.66%\n",
      "Validation loss decreased (6.838026 --> 1.132471).  Saving model ...\n",
      "Epoch: 25/500..  Training Loss: 0.004470..  Val Loss: 0.312825..  Val Accuracy: 89.09%\n",
      "Epoch: 27/500..  Training Loss: 0.003817..  Val Loss: 0.182633..  Val Accuracy: 93.91%\n",
      "Epoch: 30/500..  Training Loss: 0.000117..  Val Loss: 0.122949..  Val Accuracy: 95.83%\n",
      "Epoch: 32/500..  Training Loss: 0.000417..  Val Loss: 0.817280..  Val Accuracy: 79.56%\n",
      "Epoch: 34/500..  Training Loss: 0.000353..  Val Loss: 0.028551..  Val Accuracy: 99.04%\n",
      "Epoch: 36/500..  Training Loss: 0.000980..  Val Loss: 0.190094..  Val Accuracy: 92.86%\n",
      "Epoch: 38/500..  Training Loss: 0.001039..  Val Loss: 0.500482..  Val Accuracy: 85.42%\n",
      "Epoch: 40/500..  Training Loss: 0.000809..  Val Loss: 0.545376..  Val Accuracy: 84.32%\n",
      "Epoch: 42/500..  Training Loss: 0.000483..  Val Loss: 0.258076..  Val Accuracy: 91.90%\n",
      "Epoch: 44/500..  Training Loss: 0.001614..  Val Loss: 0.090377..  Val Accuracy: 97.21%\n",
      "Epoch: 46/500..  Training Loss: 0.000969..  Val Loss: 0.443288..  Val Accuracy: 86.61%\n",
      "Epoch: 48/500..  Training Loss: 0.001990..  Val Loss: 0.241191..  Val Accuracy: 91.61%\n",
      "Epoch: 50/500..  Training Loss: 0.000776..  Val Loss: 0.861442..  Val Accuracy: 79.92%\n",
      "Epoch: 52/500..  Training Loss: 0.002685..  Val Loss: 0.427133..  Val Accuracy: 87.14%\n",
      "Epoch: 54/500..  Training Loss: 0.001039..  Val Loss: 0.694534..  Val Accuracy: 82.24%\n",
      "Epoch: 57/500..  Training Loss: 0.000008..  Val Loss: 0.345587..  Val Accuracy: 90.36%\n",
      "Epoch: 59/500..  Training Loss: 0.000087..  Val Loss: 0.117120..  Val Accuracy: 95.94%\n",
      "Epoch: 61/500..  Training Loss: 0.000034..  Val Loss: 0.248244..  Val Accuracy: 92.63%\n",
      "Epoch: 63/500..  Training Loss: 0.000366..  Val Loss: 0.134755..  Val Accuracy: 95.94%\n",
      "Epoch: 65/500..  Training Loss: 0.000061..  Val Loss: 0.375081..  Val Accuracy: 89.45%\n",
      "Epoch: 67/500..  Training Loss: 0.000265..  Val Loss: 0.592723..  Val Accuracy: 83.12%\n",
      "Epoch: 69/500..  Training Loss: 0.000653..  Val Loss: 0.303690..  Val Accuracy: 91.82%\n",
      "Epoch: 71/500..  Training Loss: 0.000766..  Val Loss: 0.415739..  Val Accuracy: 88.44%\n",
      "Epoch: 73/500..  Training Loss: 0.000805..  Val Loss: 0.517695..  Val Accuracy: 85.76%\n",
      "Epoch: 75/500..  Training Loss: 0.000244..  Val Loss: 0.808193..  Val Accuracy: 79.71%\n",
      "Epoch: 77/500..  Training Loss: 0.001190..  Val Loss: 0.312093..  Val Accuracy: 89.53%\n",
      "Epoch: 79/500..  Training Loss: 0.000154..  Val Loss: 0.158427..  Val Accuracy: 94.61%\n",
      "Epoch: 81/500..  Training Loss: 0.000429..  Val Loss: 1.558266..  Val Accuracy: 71.33%\n",
      "Epoch: 83/500..  Training Loss: 0.002643..  Val Loss: 0.223181..  Val Accuracy: 93.20%\n",
      "Epoch: 86/500..  Training Loss: 0.000052..  Val Loss: 0.172323..  Val Accuracy: 94.74%\n",
      "Epoch: 88/500..  Training Loss: 0.000106..  Val Loss: 0.200053..  Val Accuracy: 94.14%\n",
      "Epoch: 90/500..  Training Loss: 0.000169..  Val Loss: 0.196303..  Val Accuracy: 93.65%\n",
      "Epoch: 92/500..  Training Loss: 0.000072..  Val Loss: 0.069205..  Val Accuracy: 97.60%\n",
      "Epoch: 94/500..  Training Loss: 0.000430..  Val Loss: 0.052164..  Val Accuracy: 98.39%\n",
      "Epoch: 96/500..  Training Loss: 0.000470..  Val Loss: 0.188468..  Val Accuracy: 94.32%\n",
      "Epoch: 98/500..  Training Loss: 0.000793..  Val Loss: 0.211437..  Val Accuracy: 92.84%\n",
      "Epoch: 100/500..  Training Loss: 0.000085..  Val Loss: 0.296584..  Val Accuracy: 90.83%\n",
      "Epoch: 102/500..  Training Loss: 0.001743..  Val Loss: 0.118334..  Val Accuracy: 95.68%\n",
      "Epoch: 104/500..  Training Loss: 0.000402..  Val Loss: 0.058398..  Val Accuracy: 97.71%\n",
      "Epoch: 106/500..  Training Loss: 0.001191..  Val Loss: 0.492388..  Val Accuracy: 87.66%\n",
      "Epoch: 108/500..  Training Loss: 0.001268..  Val Loss: 0.200131..  Val Accuracy: 93.49%\n",
      "Epoch: 110/500..  Training Loss: 0.000802..  Val Loss: 0.112302..  Val Accuracy: 95.89%\n",
      "Epoch: 113/500..  Training Loss: 0.000003..  Val Loss: 0.146701..  Val Accuracy: 95.29%\n",
      "Epoch: 115/500..  Training Loss: 0.000006..  Val Loss: 0.162747..  Val Accuracy: 94.84%\n",
      "Epoch: 117/500..  Training Loss: 0.000028..  Val Loss: 0.065112..  Val Accuracy: 97.86%\n",
      "Epoch: 119/500..  Training Loss: 0.000059..  Val Loss: 0.090316..  Val Accuracy: 96.64%\n",
      "Epoch: 121/500..  Training Loss: 0.000090..  Val Loss: 0.152269..  Val Accuracy: 95.26%\n",
      "Epoch: 123/500..  Training Loss: 0.000295..  Val Loss: 0.204275..  Val Accuracy: 94.04%\n",
      "Epoch: 125/500..  Training Loss: 0.000226..  Val Loss: 0.172664..  Val Accuracy: 95.34%\n",
      "Epoch: 127/500..  Training Loss: 0.000912..  Val Loss: 0.253515..  Val Accuracy: 92.63%\n",
      "Epoch: 129/500..  Training Loss: 0.000408..  Val Loss: 0.075105..  Val Accuracy: 97.71%\n",
      "Epoch: 131/500..  Training Loss: 0.000215..  Val Loss: 0.087529..  Val Accuracy: 97.50%\n",
      "Epoch: 133/500..  Training Loss: 0.000099..  Val Loss: 0.084342..  Val Accuracy: 97.21%\n",
      "Epoch: 135/500..  Training Loss: 0.003065..  Val Loss: 0.491115..  Val Accuracy: 89.71%\n",
      "Epoch: 137/500..  Training Loss: 0.000804..  Val Loss: 0.230370..  Val Accuracy: 94.30%\n",
      "Epoch: 140/500..  Training Loss: 0.000008..  Val Loss: 0.051528..  Val Accuracy: 98.62%\n",
      "Epoch: 142/500..  Training Loss: 0.000022..  Val Loss: 0.067478..  Val Accuracy: 97.79%\n",
      "Epoch: 144/500..  Training Loss: 0.000142..  Val Loss: 0.088706..  Val Accuracy: 97.34%\n",
      "Epoch: 146/500..  Training Loss: 0.000114..  Val Loss: 0.158444..  Val Accuracy: 95.44%\n",
      "Epoch: 148/500..  Training Loss: 0.000033..  Val Loss: 0.353012..  Val Accuracy: 90.49%\n",
      "Epoch: 150/500..  Training Loss: 0.000218..  Val Loss: 0.843597..  Val Accuracy: 82.79%\n",
      "Epoch: 152/500..  Training Loss: 0.000049..  Val Loss: 0.086405..  Val Accuracy: 97.29%\n",
      "Epoch: 154/500..  Training Loss: 0.000341..  Val Loss: 0.272687..  Val Accuracy: 92.50%\n",
      "Epoch: 156/500..  Training Loss: 0.000644..  Val Loss: 0.202460..  Val Accuracy: 93.93%\n",
      "Epoch: 158/500..  Training Loss: 0.000091..  Val Loss: 0.501714..  Val Accuracy: 87.86%\n",
      "Epoch: 160/500..  Training Loss: 0.000058..  Val Loss: 0.151680..  Val Accuracy: 95.62%\n",
      "Epoch: 162/500..  Training Loss: 0.000674..  Val Loss: 0.034103..  Val Accuracy: 98.96%\n",
      "Epoch: 164/500..  Training Loss: 0.000067..  Val Loss: 0.096962..  Val Accuracy: 96.80%\n",
      "Epoch: 166/500..  Training Loss: 0.000526..  Val Loss: 0.021166..  Val Accuracy: 99.40%\n",
      "Epoch: 169/500..  Training Loss: 0.000034..  Val Loss: 0.341981..  Val Accuracy: 91.15%\n",
      "Epoch: 171/500..  Training Loss: 0.000023..  Val Loss: 0.221281..  Val Accuracy: 93.46%\n",
      "Epoch: 173/500..  Training Loss: 0.000693..  Val Loss: 0.107066..  Val Accuracy: 96.67%\n",
      "Epoch: 175/500..  Training Loss: 0.000252..  Val Loss: 0.855511..  Val Accuracy: 82.66%\n",
      "Epoch: 177/500..  Training Loss: 0.000110..  Val Loss: 0.203993..  Val Accuracy: 94.40%\n",
      "Epoch: 179/500..  Training Loss: 0.000255..  Val Loss: 0.249409..  Val Accuracy: 92.84%\n",
      "Epoch: 181/500..  Training Loss: 0.000024..  Val Loss: 0.078106..  Val Accuracy: 97.40%\n",
      "Epoch: 183/500..  Training Loss: 0.000211..  Val Loss: 0.089589..  Val Accuracy: 97.63%\n",
      "Epoch: 185/500..  Training Loss: 0.000240..  Val Loss: 0.062646..  Val Accuracy: 97.99%\n",
      "Epoch: 187/500..  Training Loss: 0.000483..  Val Loss: 0.087901..  Val Accuracy: 96.88%\n",
      "Epoch: 189/500..  Training Loss: 0.000234..  Val Loss: 0.005801..  Val Accuracy: 99.77%\n",
      "Validation loss decreased (1.132471 --> 0.696119).  Saving model ...\n",
      "Epoch: 191/500..  Training Loss: 0.000471..  Val Loss: 0.090384..  Val Accuracy: 96.98%\n",
      "Epoch: 193/500..  Training Loss: 0.000031..  Val Loss: 0.372687..  Val Accuracy: 90.26%\n",
      "Epoch: 196/500..  Training Loss: 0.000003..  Val Loss: 0.090220..  Val Accuracy: 97.42%\n",
      "Epoch: 198/500..  Training Loss: 0.000005..  Val Loss: 0.118448..  Val Accuracy: 96.72%\n",
      "Epoch: 200/500..  Training Loss: 0.000001..  Val Loss: 0.177101..  Val Accuracy: 95.31%\n",
      "Epoch: 202/500..  Training Loss: 0.000083..  Val Loss: 0.164077..  Val Accuracy: 94.97%\n",
      "Epoch: 204/500..  Training Loss: 0.000045..  Val Loss: 0.107801..  Val Accuracy: 96.61%\n",
      "Epoch: 206/500..  Training Loss: 0.000215..  Val Loss: 0.146679..  Val Accuracy: 95.34%\n",
      "Epoch: 208/500..  Training Loss: 0.000375..  Val Loss: 0.230850..  Val Accuracy: 93.31%\n",
      "Epoch: 210/500..  Training Loss: 0.000041..  Val Loss: 0.060091..  Val Accuracy: 97.84%\n",
      "Epoch: 212/500..  Training Loss: 0.000021..  Val Loss: 0.249218..  Val Accuracy: 93.10%\n",
      "Epoch: 214/500..  Training Loss: 0.000189..  Val Loss: 0.109941..  Val Accuracy: 96.64%\n",
      "Epoch: 216/500..  Training Loss: 0.000564..  Val Loss: 0.154576..  Val Accuracy: 95.62%\n",
      "Epoch: 218/500..  Training Loss: 0.000619..  Val Loss: 0.037552..  Val Accuracy: 98.83%\n",
      "Epoch: 220/500..  Training Loss: 0.000183..  Val Loss: 0.176467..  Val Accuracy: 94.87%\n",
      "Epoch: 222/500..  Training Loss: 0.000038..  Val Loss: 0.088174..  Val Accuracy: 97.34%\n",
      "Epoch: 225/500..  Training Loss: 0.000003..  Val Loss: 0.302270..  Val Accuracy: 93.23%\n",
      "Epoch: 227/500..  Training Loss: 0.000057..  Val Loss: 0.185186..  Val Accuracy: 95.26%\n",
      "Epoch: 229/500..  Training Loss: 0.000028..  Val Loss: 0.201780..  Val Accuracy: 94.40%\n",
      "Epoch: 231/500..  Training Loss: 0.000014..  Val Loss: 0.084589..  Val Accuracy: 97.42%\n",
      "Epoch: 233/500..  Training Loss: 0.000021..  Val Loss: 0.095977..  Val Accuracy: 97.14%\n",
      "Epoch: 235/500..  Training Loss: 0.000041..  Val Loss: 0.112557..  Val Accuracy: 96.46%\n",
      "Epoch: 237/500..  Training Loss: 0.000043..  Val Loss: 0.147537..  Val Accuracy: 96.07%\n",
      "Epoch: 239/500..  Training Loss: 0.001541..  Val Loss: 0.030010..  Val Accuracy: 99.19%\n",
      "Epoch: 241/500..  Training Loss: 0.000152..  Val Loss: 0.092034..  Val Accuracy: 96.95%\n",
      "Epoch: 243/500..  Training Loss: 0.000028..  Val Loss: 0.108889..  Val Accuracy: 96.69%\n",
      "Epoch: 245/500..  Training Loss: 0.000024..  Val Loss: 0.112446..  Val Accuracy: 96.67%\n",
      "Epoch: 247/500..  Training Loss: 0.000035..  Val Loss: 0.016435..  Val Accuracy: 99.56%\n",
      "Epoch: 249/500..  Training Loss: 0.001092..  Val Loss: 0.113727..  Val Accuracy: 96.54%\n",
      "Epoch: 252/500..  Training Loss: 0.000002..  Val Loss: 0.077700..  Val Accuracy: 97.40%\n",
      "Epoch: 254/500..  Training Loss: 0.000005..  Val Loss: 0.040674..  Val Accuracy: 98.75%\n",
      "Epoch: 256/500..  Training Loss: 0.000116..  Val Loss: 0.092657..  Val Accuracy: 97.37%\n",
      "Epoch: 258/500..  Training Loss: 0.000323..  Val Loss: 0.122424..  Val Accuracy: 96.69%\n",
      "Epoch: 260/500..  Training Loss: 0.000056..  Val Loss: 0.062773..  Val Accuracy: 98.28%\n",
      "Epoch: 262/500..  Training Loss: 0.000008..  Val Loss: 0.200941..  Val Accuracy: 94.40%\n",
      "Epoch: 264/500..  Training Loss: 0.000141..  Val Loss: 0.058091..  Val Accuracy: 98.52%\n",
      "Epoch: 266/500..  Training Loss: 0.000279..  Val Loss: 0.051032..  Val Accuracy: 98.49%\n",
      "Epoch: 268/500..  Training Loss: 0.000108..  Val Loss: 0.044788..  Val Accuracy: 98.52%\n",
      "Epoch: 270/500..  Training Loss: 0.000021..  Val Loss: 0.090725..  Val Accuracy: 97.34%\n",
      "Epoch: 272/500..  Training Loss: 0.000030..  Val Loss: 0.076175..  Val Accuracy: 97.89%\n",
      "Epoch: 274/500..  Training Loss: 0.000219..  Val Loss: 0.108688..  Val Accuracy: 96.90%\n",
      "Epoch: 276/500..  Training Loss: 0.000229..  Val Loss: 0.066499..  Val Accuracy: 98.67%\n",
      "Epoch: 279/500..  Training Loss: 0.000000..  Val Loss: 0.096787..  Val Accuracy: 97.21%\n",
      "Epoch: 281/500..  Training Loss: 0.001272..  Val Loss: 9.031508..  Val Accuracy: 52.34%\n",
      "Epoch: 283/500..  Training Loss: 0.000005..  Val Loss: 0.205159..  Val Accuracy: 94.84%\n",
      "Epoch: 285/500..  Training Loss: 0.000047..  Val Loss: 0.077753..  Val Accuracy: 97.47%\n",
      "Epoch: 287/500..  Training Loss: 0.000035..  Val Loss: 0.163103..  Val Accuracy: 94.92%\n",
      "Epoch: 289/500..  Training Loss: 0.000015..  Val Loss: 0.134457..  Val Accuracy: 95.83%\n",
      "Epoch: 291/500..  Training Loss: 0.000009..  Val Loss: 0.111295..  Val Accuracy: 96.85%\n",
      "Epoch: 293/500..  Training Loss: 0.000820..  Val Loss: 0.208483..  Val Accuracy: 94.38%\n",
      "Epoch: 295/500..  Training Loss: 0.000019..  Val Loss: 0.297148..  Val Accuracy: 92.53%\n",
      "Epoch: 297/500..  Training Loss: 0.000014..  Val Loss: 0.178060..  Val Accuracy: 94.97%\n",
      "Epoch: 299/500..  Training Loss: 0.000172..  Val Loss: 0.165459..  Val Accuracy: 95.39%\n",
      "Epoch: 301/500..  Training Loss: 0.000052..  Val Loss: 0.132598..  Val Accuracy: 96.07%\n",
      "Epoch: 303/500..  Training Loss: 0.000091..  Val Loss: 0.032933..  Val Accuracy: 98.93%\n",
      "Epoch: 305/500..  Training Loss: 0.000205..  Val Loss: 0.222692..  Val Accuracy: 94.01%\n",
      "Epoch: 308/500..  Training Loss: 0.000704..  Val Loss: 0.005136..  Val Accuracy: 99.87%\n",
      "Validation loss decreased (0.696119 --> 0.616333).  Saving model ...\n",
      "Epoch: 310/500..  Training Loss: 0.000021..  Val Loss: 0.181842..  Val Accuracy: 95.76%\n",
      "Epoch: 312/500..  Training Loss: 0.000037..  Val Loss: 0.154082..  Val Accuracy: 95.89%\n",
      "Epoch: 314/500..  Training Loss: 0.000181..  Val Loss: 0.194777..  Val Accuracy: 95.36%\n",
      "Epoch: 316/500..  Training Loss: 0.000013..  Val Loss: 0.058948..  Val Accuracy: 98.15%\n",
      "Epoch: 318/500..  Training Loss: 0.000012..  Val Loss: 0.101029..  Val Accuracy: 97.03%\n",
      "Epoch: 320/500..  Training Loss: 0.000381..  Val Loss: 0.164751..  Val Accuracy: 95.68%\n",
      "Epoch: 322/500..  Training Loss: 0.000121..  Val Loss: 0.126583..  Val Accuracy: 95.91%\n",
      "Epoch: 324/500..  Training Loss: 0.000148..  Val Loss: 0.067675..  Val Accuracy: 97.81%\n",
      "Epoch: 326/500..  Training Loss: 0.000788..  Val Loss: 0.016482..  Val Accuracy: 99.61%\n",
      "Epoch: 328/500..  Training Loss: 0.000097..  Val Loss: 0.126147..  Val Accuracy: 95.73%\n",
      "Epoch: 330/500..  Training Loss: 0.000013..  Val Loss: 0.087588..  Val Accuracy: 97.34%\n",
      "Epoch: 332/500..  Training Loss: 0.001353..  Val Loss: 0.058123..  Val Accuracy: 98.26%\n",
      "Epoch: 335/500..  Training Loss: 0.000000..  Val Loss: 0.111656..  Val Accuracy: 96.93%\n",
      "Epoch: 337/500..  Training Loss: 0.000003..  Val Loss: 0.050295..  Val Accuracy: 98.49%\n",
      "Epoch: 339/500..  Training Loss: 0.000130..  Val Loss: 0.084050..  Val Accuracy: 97.71%\n",
      "Epoch: 341/500..  Training Loss: 0.000009..  Val Loss: 0.067019..  Val Accuracy: 98.12%\n",
      "Epoch: 343/500..  Training Loss: 0.000002..  Val Loss: 0.084246..  Val Accuracy: 97.45%\n",
      "Epoch: 345/500..  Training Loss: 0.000078..  Val Loss: 0.042236..  Val Accuracy: 99.04%\n",
      "Epoch: 347/500..  Training Loss: 0.000011..  Val Loss: 0.098378..  Val Accuracy: 96.82%\n",
      "Epoch: 349/500..  Training Loss: 0.000011..  Val Loss: 0.117924..  Val Accuracy: 96.51%\n",
      "Epoch: 351/500..  Training Loss: 0.000971..  Val Loss: 0.095106..  Val Accuracy: 97.03%\n",
      "Epoch: 353/500..  Training Loss: 0.000053..  Val Loss: 0.133224..  Val Accuracy: 96.22%\n",
      "Epoch: 355/500..  Training Loss: 0.000158..  Val Loss: 0.078195..  Val Accuracy: 97.68%\n",
      "Epoch: 357/500..  Training Loss: 0.000575..  Val Loss: 0.042601..  Val Accuracy: 98.62%\n",
      "Epoch: 359/500..  Training Loss: 0.001078..  Val Loss: 0.021362..  Val Accuracy: 99.35%\n",
      "Epoch: 361/500..  Training Loss: 0.000080..  Val Loss: 0.073507..  Val Accuracy: 97.40%\n",
      "Epoch: 364/500..  Training Loss: 0.000008..  Val Loss: 0.105774..  Val Accuracy: 97.03%\n",
      "Epoch: 366/500..  Training Loss: 0.000010..  Val Loss: 0.103582..  Val Accuracy: 96.69%\n",
      "Epoch: 368/500..  Training Loss: 0.000003..  Val Loss: 0.086511..  Val Accuracy: 97.60%\n",
      "Epoch: 370/500..  Training Loss: 0.000001..  Val Loss: 0.063095..  Val Accuracy: 98.31%\n",
      "Epoch: 372/500..  Training Loss: 0.000092..  Val Loss: 0.056616..  Val Accuracy: 98.46%\n",
      "Epoch: 374/500..  Training Loss: 0.000064..  Val Loss: 0.068583..  Val Accuracy: 97.81%\n",
      "Epoch: 376/500..  Training Loss: 0.000023..  Val Loss: 0.072614..  Val Accuracy: 97.89%\n",
      "Epoch: 378/500..  Training Loss: 0.000038..  Val Loss: 0.146911..  Val Accuracy: 96.35%\n",
      "Epoch: 380/500..  Training Loss: 0.000254..  Val Loss: 0.105014..  Val Accuracy: 97.01%\n",
      "Epoch: 382/500..  Training Loss: 0.000010..  Val Loss: 0.128626..  Val Accuracy: 96.20%\n",
      "Epoch: 384/500..  Training Loss: 0.000022..  Val Loss: 0.360058..  Val Accuracy: 91.43%\n",
      "Epoch: 386/500..  Training Loss: 0.000456..  Val Loss: 0.084558..  Val Accuracy: 97.24%\n",
      "Epoch: 388/500..  Training Loss: 0.000165..  Val Loss: 0.024155..  Val Accuracy: 99.35%\n",
      "Epoch: 391/500..  Training Loss: 0.000002..  Val Loss: 0.102983..  Val Accuracy: 96.59%\n",
      "Epoch: 393/500..  Training Loss: 0.000001..  Val Loss: 0.136702..  Val Accuracy: 96.07%\n",
      "Epoch: 395/500..  Training Loss: 0.000035..  Val Loss: 0.068447..  Val Accuracy: 97.76%\n",
      "Epoch: 397/500..  Training Loss: 0.000008..  Val Loss: 0.202815..  Val Accuracy: 94.97%\n",
      "Epoch: 399/500..  Training Loss: 0.000010..  Val Loss: 0.042169..  Val Accuracy: 98.70%\n",
      "Epoch: 401/500..  Training Loss: 0.000012..  Val Loss: 0.085378..  Val Accuracy: 97.24%\n",
      "Epoch: 403/500..  Training Loss: 0.000011..  Val Loss: 0.056484..  Val Accuracy: 98.10%\n",
      "Epoch: 405/500..  Training Loss: 0.000080..  Val Loss: 0.012369..  Val Accuracy: 99.61%\n",
      "Epoch: 407/500..  Training Loss: 0.000012..  Val Loss: 0.103112..  Val Accuracy: 97.03%\n",
      "Epoch: 409/500..  Training Loss: 0.000084..  Val Loss: 0.263692..  Val Accuracy: 94.06%\n",
      "Epoch: 411/500..  Training Loss: 0.001246..  Val Loss: 0.110988..  Val Accuracy: 96.46%\n",
      "Epoch: 413/500..  Training Loss: 0.000092..  Val Loss: 0.163933..  Val Accuracy: 95.29%\n",
      "Epoch: 415/500..  Training Loss: 0.000146..  Val Loss: 0.323299..  Val Accuracy: 91.67%\n",
      "Epoch: 418/500..  Training Loss: 0.000000..  Val Loss: 0.065609..  Val Accuracy: 97.73%\n",
      "Epoch: 420/500..  Training Loss: 0.000001..  Val Loss: 0.062138..  Val Accuracy: 97.97%\n",
      "Epoch: 422/500..  Training Loss: 0.000000..  Val Loss: 0.050997..  Val Accuracy: 98.28%\n",
      "Epoch: 424/500..  Training Loss: 0.000638..  Val Loss: 0.045848..  Val Accuracy: 98.80%\n",
      "Epoch: 426/500..  Training Loss: 0.000017..  Val Loss: 0.026022..  Val Accuracy: 99.14%\n",
      "Epoch: 428/500..  Training Loss: 0.000038..  Val Loss: 0.075282..  Val Accuracy: 97.42%\n",
      "Epoch: 430/500..  Training Loss: 0.000215..  Val Loss: 0.042061..  Val Accuracy: 98.57%\n",
      "Epoch: 432/500..  Training Loss: 0.000005..  Val Loss: 0.037635..  Val Accuracy: 98.75%\n",
      "Epoch: 434/500..  Training Loss: 0.000002..  Val Loss: 0.055185..  Val Accuracy: 98.20%\n",
      "Epoch: 436/500..  Training Loss: 0.000216..  Val Loss: 0.206033..  Val Accuracy: 94.38%\n",
      "Epoch: 438/500..  Training Loss: 0.000218..  Val Loss: 0.084241..  Val Accuracy: 97.42%\n",
      "Epoch: 440/500..  Training Loss: 0.000027..  Val Loss: 0.091175..  Val Accuracy: 97.21%\n",
      "Epoch: 442/500..  Training Loss: 0.000032..  Val Loss: 0.291415..  Val Accuracy: 92.76%\n",
      "Epoch: 444/500..  Training Loss: 0.000034..  Val Loss: 0.306622..  Val Accuracy: 92.89%\n",
      "Epoch: 447/500..  Training Loss: 0.000001..  Val Loss: 0.107867..  Val Accuracy: 96.77%\n",
      "Epoch: 449/500..  Training Loss: 0.000020..  Val Loss: 0.070457..  Val Accuracy: 97.68%\n",
      "Epoch: 451/500..  Training Loss: 0.000008..  Val Loss: 0.217049..  Val Accuracy: 94.27%\n",
      "Epoch: 453/500..  Training Loss: 0.000028..  Val Loss: 0.187107..  Val Accuracy: 94.71%\n",
      "Epoch: 455/500..  Training Loss: 0.000004..  Val Loss: 0.147524..  Val Accuracy: 96.04%\n",
      "Epoch: 457/500..  Training Loss: 0.000978..  Val Loss: 0.082471..  Val Accuracy: 97.08%\n",
      "Epoch: 459/500..  Training Loss: 0.000021..  Val Loss: 0.077749..  Val Accuracy: 97.45%\n",
      "Epoch: 461/500..  Training Loss: 0.000008..  Val Loss: 0.079237..  Val Accuracy: 97.19%\n",
      "Epoch: 463/500..  Training Loss: 0.000006..  Val Loss: 0.110660..  Val Accuracy: 96.35%\n",
      "Epoch: 465/500..  Training Loss: 0.000147..  Val Loss: 0.282714..  Val Accuracy: 91.64%\n",
      "Epoch: 467/500..  Training Loss: 0.000016..  Val Loss: 0.070288..  Val Accuracy: 97.50%\n",
      "Epoch: 469/500..  Training Loss: 0.000280..  Val Loss: 0.182767..  Val Accuracy: 95.13%\n",
      "Epoch: 471/500..  Training Loss: 0.000218..  Val Loss: 0.125746..  Val Accuracy: 96.15%\n",
      "Epoch: 474/500..  Training Loss: 0.000000..  Val Loss: 0.132583..  Val Accuracy: 95.94%\n",
      "Epoch: 476/500..  Training Loss: 0.000006..  Val Loss: 0.048918..  Val Accuracy: 98.20%\n",
      "Epoch: 478/500..  Training Loss: 0.000001..  Val Loss: 0.113786..  Val Accuracy: 96.59%\n",
      "Epoch: 480/500..  Training Loss: 0.000005..  Val Loss: 0.069290..  Val Accuracy: 98.02%\n",
      "Epoch: 482/500..  Training Loss: 0.000019..  Val Loss: 0.090016..  Val Accuracy: 96.98%\n",
      "Epoch: 484/500..  Training Loss: 0.000014..  Val Loss: 0.069154..  Val Accuracy: 97.32%\n",
      "Epoch: 486/500..  Training Loss: 0.000007..  Val Loss: 0.071107..  Val Accuracy: 97.37%\n",
      "Epoch: 488/500..  Training Loss: 0.000031..  Val Loss: 0.035549..  Val Accuracy: 98.96%\n",
      "Epoch: 490/500..  Training Loss: 0.000014..  Val Loss: 0.183647..  Val Accuracy: 95.05%\n",
      "Epoch: 492/500..  Training Loss: 0.000033..  Val Loss: 0.040076..  Val Accuracy: 98.65%\n",
      "Epoch: 494/500..  Training Loss: 0.000035..  Val Loss: 0.191271..  Val Accuracy: 94.61%\n",
      "Epoch: 496/500..  Training Loss: 0.000012..  Val Loss: 0.083512..  Val Accuracy: 97.29%\n",
      "Epoch: 498/500..  Training Loss: 0.000209..  Val Loss: 0.218929..  Val Accuracy: 95.44%\n",
      "Epoch: 500/500..  Training Loss: 0.000568..  Val Loss: 0.087775..  Val Accuracy: 97.27%\n"
     ]
    }
   ],
   "source": [
    "model1=final(modelll,traindataloader,validdataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4ee6b6f-429e-4f17-9979-9734b0b2b919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_test_1500_10.npy', 'x_test_2700_25.npy', 'y_test_1500_10.npy', 'y_test_2700_25.npy', 'z_test_1500_10.npy', 'z_test_2700_25.npy']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"../data/testset\"\n",
    "file_list = os.listdir(path)\n",
    "print(file_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54d6d412-050d-4b00-9fce-8385e0d66eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1500_10=np.load(\"../data/testset/\"+file_list[0])\n",
    "y_test_1500_10=np.load(\"../data/testset/\"+file_list[2])\n",
    "z_test_1500_10=np.load(\"../data/testset/\"+file_list[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22d2a98a-fde4-439a-bb7f-16e3feb45a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1500=np.concatenate((np.expand_dims(x_test_1500_10, axis=1),np.expand_dims(y_test_1500_10, axis=1),np.expand_dims(z_test_1500_10, axis=1)),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09b2f135-0321-4fbf-a745-aa519c53d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#depthwise version\n",
    "class customdataset2(Dataset):\n",
    "    def __init__(self, data): \n",
    "        super().__init__()\n",
    "        self.data=torch.tensor(data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "                \n",
    "        return  x.to(device).float()\n",
    "testdataset_1500 = customdataset2(data_1500)\n",
    "testdataloader_1500 = DataLoader(testdataset_1500, batch_size=1, shuffle=False, drop_last=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d74db1-e79a-4fc7-8fa8-2e8970480394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346f604-64f3-413a-a19c-5d2770b52b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25b062ca-7217-4367-9f73-75492590ebee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelll.load_state_dict(torch.load('./malstm_msn_cv_cond_1_esb_1_2.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "300e67ba-0877-4929-91ab-fdcdfa48b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1and2diagnosis=test(modelll,testdataloader_1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d47c003-e656-4822-b761-07fec67609fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1, dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1and2diagnosis[6778]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae3863e7-e3e7-4956-8176-17e98c934a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1and2diagnosis[11008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84b39050-e395-48f2-b7d2-b22fced03a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1and2diagnosis[11413]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8080b2d9-0dd1-4607-b780-10773fc3014e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0, dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1and2diagnosis[12759]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f01a0-d314-47bc-a27f-136611f5ad0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97825729-2135-400e-99c1-7d0c526c38b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab03c2-1382-4b96-bbe7-853c9cd8495a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2740b3e-bc89-4d2e-9c88-9e9d40db8acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
