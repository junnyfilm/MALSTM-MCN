{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e69afd-a28e-4614-a0cb-b8175f53a740",
   "metadata": {},
   "source": [
    "## 앙상블 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a883b28-8116-4e84-8e76-67abeb292951",
   "metadata": {},
   "source": [
    "- cv값이랑 cond값 지정해주세요 cv 5, cond 2 , 내부 앙상블 5개 => 총 50개 모델 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3cd2321-b65d-47a4-9efa-23314bdb0962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv=4\n",
    "cond=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f799a1-ddfc-4159-8de8-165d7f76bf0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from numpy import inf\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import pickle\n",
    "import argparse, sys, os\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "import torchvision.transforms.functional as Fv\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchsummary import summary\n",
    "from torch.optim import lr_scheduler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch import topk\n",
    "from tqdm.notebook import tqdm # 프로세스 바\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "# device = torch.device(\"cuda:%d\" % 0 if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "# from dataloader_hilbert_att import DataLoader\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b8c41b-2954-4211-a543-dad65a5369f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path= \"\\\\\\\\147.47.239.143\\\\SHRM-robotgear\\\\ICPHM2023\\\\pickle\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "484b5952-58a5-4748-b062-93175e206d37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # read data\n",
    "\n",
    "with open(path+'cross_val_train_set_'+str(cv)+'_'+str(cond)+'.pickle', 'rb') as f:\n",
    "    cross_val_train_set = pickle.load(f)\n",
    "with open(path+'cross_val_train_label_'+str(cv)+'_'+str(cond)+'.pickle', 'rb') as f:\n",
    "    cross_val_train_label = pickle.load(f)\n",
    "with open(path+'cross_val_test_set_'+str(cv)+'_'+str(cond)+'.pickle', 'rb') as f:\n",
    "    cross_val_test_set = pickle.load(f)\n",
    "with open(path+'cross_val_test_label_'+str(cv)+'_'+str(cond)+'.pickle', 'rb') as f:\n",
    "    cross_val_test_label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cad946e-c35f-4762-9647-dc6488cc4352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#depthwise version\n",
    "class customdataset(Dataset):\n",
    "    def __init__(self, data, label): \n",
    "        super().__init__()\n",
    "        self.data=torch.tensor(data)\n",
    "        self.label=torch.tensor(label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        label = self.label[idx] \n",
    "                \n",
    "        return  x.to(device).float(), label.to(device).long()\n",
    "\n",
    "def loaders(tr_data,tr_label,ts_data,ts_label,random_state):\n",
    "    train_set, valid_set, train_label, valid_label = train_test_split(tr_data, tr_label,random_state=random_state, train_size=0.75)\n",
    "    \n",
    "    traindataset = customdataset(train_set, train_label)\n",
    "    validdataset = customdataset(valid_set, valid_label)\n",
    "    testdataset = customdataset(ts_data, ts_label)\n",
    "    \n",
    "    traindataloader = DataLoader(traindataset, batch_size=32, shuffle=True, drop_last=True )\n",
    "    validdataloader = DataLoader(validdataset, batch_size=32, shuffle=True, drop_last=True )\n",
    "    testdataloader = DataLoader(testdataset, batch_size=1, shuffle=False, drop_last=False )\n",
    "    \n",
    "    return traindataloader,validdataloader,testdataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8771177-fe83-4f73-b2d1-b12590ff3b1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f19a6ca-b731-4775-af5f-708bcc055787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "savepath= './'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a6adc-be63-49c7-b19f-a33b77237cde",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 기본 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f78f6216-a72c-44a4-a138-fd819810c83f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7efd1e-386a-484f-aefa-31da02d7bbdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dilated_Module(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Dilated_Module,self).__init__()\n",
    "        self.conv1=nn.Conv1d(in_channels, int(out_channels/4), kernel_size = 5, stride = 1, padding = ((5)//2), dilation=1, bias=False)        \n",
    "        self.conv2=nn.Conv1d(in_channels, int(out_channels/4), kernel_size = 5, stride = 1, padding = ((5+4*2)//2), dilation=3, bias=False)        \n",
    "        self.conv3=nn.Conv1d(in_channels, int(out_channels/4), kernel_size = 5, stride = 1, padding = ((5+4*4)//2), dilation=5, bias=False)\n",
    "        self.conv4=nn.Conv1d(in_channels, int(out_channels/4), kernel_size = 5, stride = 1, padding = ((5+4*6)//2), dilation=7, bias=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        ''' input x should be in size [B,F,T], where \n",
    "            B = Batch size\n",
    "            F = features\n",
    "            T = Time samples\n",
    "        '''\n",
    "        x1=self.conv1(x)\n",
    "        x2=self.conv2(x)\n",
    "        x3=self.conv3(x)\n",
    "        x4=self.conv4(x)\n",
    "        \n",
    "        y=torch.cat([x1,x2,x3,x4],dim=1)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ecb90b4-6f6b-4f70-b312-cce7166881d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLSTMfcn_MSN(nn.Module):\n",
    "    def __init__(self, *, num_classes, num_features,\n",
    "                 num_lstm_out, num_lstm_layers=1, \n",
    "                 conv1_nf=128, conv2_nf=256, conv3_nf=128,\n",
    "                 lstm_drop_p=0.8, fc_drop_p=0.3):\n",
    "        super(MLSTMfcn_MSN, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.num_lstm_out = num_lstm_out\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "\n",
    "        \n",
    "        self.conv1_nf = conv1_nf\n",
    "        self.conv2_nf = conv2_nf\n",
    "        self.conv3_nf = conv3_nf\n",
    "\n",
    "        self.dilated_1=Dilated_Module(self.num_features, self.conv1_nf)\n",
    "        self.dilated_2=Dilated_Module(self.conv1_nf, self.conv2_nf)\n",
    "        self.dilated_3=Dilated_Module(self.conv2_nf, self.conv3_nf)\n",
    "\n",
    "        self.lstm_drop_p = lstm_drop_p\n",
    "        self.fc_drop_p = fc_drop_p\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.num_features, \n",
    "                            hidden_size=self.num_lstm_out,\n",
    "                            num_layers=self.num_lstm_layers,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(self.conv1_nf)\n",
    "        self.bn2 = nn.BatchNorm1d(self.conv2_nf)\n",
    "        self.bn3 = nn.BatchNorm1d(self.conv3_nf)\n",
    "\n",
    "        self.se1 = SELayer(self.conv1_nf)  # ex 128\n",
    "        self.se2 = SELayer(self.conv2_nf)  # ex 256\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstmDrop = nn.Dropout(self.lstm_drop_p)\n",
    "        self.convDrop = nn.Dropout(self.fc_drop_p)\n",
    "\n",
    "        self.fc = nn.Linear(self.conv3_nf+self.num_lstm_out, self.num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ''' input x should be in size [B,T,F], where \n",
    "            B = Batch size\n",
    "            T = Time samples\n",
    "            F = features\n",
    "        '''\n",
    "        x=x.transpose(2,1)\n",
    "        ''' input x should be in size [B,T,F], where \n",
    "            B = Batch size\n",
    "            T = Time samples\n",
    "            F = features\n",
    "        '''       \n",
    "        # x1 = nn.utils.rnn.pack_padded_sequence(x, seq_lens, \n",
    "        #                                        batch_first=True, \n",
    "        #                                        enforce_sorted=False)\n",
    "        x1, (ht,ct) = self.lstm(x)\n",
    "        x1 = self.lstmDrop(x1)\n",
    "        # x1, _ = nn.utils.rnn.pad_packed_sequence(x1, batch_first=True, \n",
    "        #                                          padding_value=0.0)\n",
    "        # print(x1.size())\n",
    "        x1 = x1[:,-1,:]\n",
    "        \n",
    "        x2 = x.transpose(2,1)\n",
    "        x2 = self.convDrop(self.relu(self.bn1(self.dilated_1(x2))))\n",
    "        # print(x2.size())\n",
    "        x2 = self.se1(x2)\n",
    "        x2 = self.convDrop(self.relu(self.bn2(self.dilated_2(x2))))\n",
    "        # print(x2.size())\n",
    "        x2 = self.se2(x2)\n",
    "        x2 = self.convDrop(self.relu(self.bn3(self.dilated_3(x2))))\n",
    "        # print(x2.size())\n",
    "        x2 = torch.mean(x2,2)\n",
    "        \n",
    "        x_all = torch.cat((x1,x2),dim=1)\n",
    "        x_out = self.fc(x_all)\n",
    "        x_out = F.log_softmax(x_out, dim=1)\n",
    "\n",
    "        return x_out,x_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388992d9-1d9c-40b5-9dd3-4effe3eb9e8a",
   "metadata": {},
   "source": [
    "### 공통실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f084af-b60b-456d-ac62-003e1a66ae4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation(model, testloader, criterion):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for inputs, labels in testloader:\n",
    "        inputs = inputs.float()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        output,_ = model.forward(inputs)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ## Calculating the accuracy \n",
    "        # Model's output is log-softmax, take exponential to get the probabilities\n",
    "        ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8cb164-562c-4ce9-9445-4d6b6c1fcf9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fail_index(pred, real, cross_val_num):\n",
    "    failed=[]\n",
    "    with open('test_fold_index_2.pickle', 'rb') as f:\n",
    "        test_fold_index = pickle.load(f)\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        if pred[i].item()!=real[i].detach().cpu().item():\n",
    "            failed.append(test_fold_index[cross_val_num-1][i])\n",
    "    \n",
    "    return failed\n",
    "\n",
    "import seaborn as sn\n",
    "def confusionmatrix(y_pred1, y_test1, column=['class0','class1','class2','class3','class4']):\n",
    "    # y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    # _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    a=[]\n",
    "    b=[]\n",
    "    for i in range(len(y_test1)):\n",
    "        a.append(y_test1[i].detach().cpu().item())\n",
    "        b.append(y_pred1[i].item())\n",
    "    y_test=a\n",
    "    y_pred=b\n",
    "    df_cm = pd.DataFrame(confusion_matrix(y_test,y_pred))\n",
    "    df_cm.index=column\n",
    "    df_cm.columns=column\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    b, t = plt.ylim() \n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t)\n",
    "    \n",
    "\n",
    "    df_cm =df_cm / df_cm.astype(np.float).sum(axis=1)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    b, t = plt.ylim() \n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t)\n",
    "\n",
    "    \n",
    "def test(classifier, dataloader):\n",
    "    # setup the network\n",
    "    predlist=[]\n",
    "    real=[]    \n",
    "\n",
    "    classifier.eval()\n",
    "    correct = 0.0\n",
    "    \n",
    "    max_tr_score = 0\n",
    "    max_val_score = 0\n",
    "    for batch_idx, (data) in enumerate(dataloader):\n",
    "    \n",
    "        signal1,label = data\n",
    "        signal1,label = Variable(signal1.cuda()),Variable(label.cuda().long())\n",
    "        out,_ = classifier(signal1)   \n",
    "\n",
    "        pred = out.data.max(1, keepdim= True)[1]\n",
    "        predlist.append(pred.cpu().detach().numpy().squeeze())\n",
    "        real.append(label)        \n",
    "        correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        # predlist.append(pred)\n",
    "    print('\\nAccuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        correct, len(dataloader.dataset), 100. * float(correct) / len(dataloader.dataset)))\n",
    "    acc=100. * float(correct) / len(dataloader.dataset)\n",
    "    return acc,predlist,real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66d4b582-2db2-42ca-af1e-5eafb3da0669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.0005, 0.0001],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'hidden_size': [8, 64, 128],\n",
    "    'optimizer': ['Adam', 'RMSprop', 'SGD']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de024bea-2b4f-415c-8887-08f348e64af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = param_grid['lr'][0]\n",
    "batch_size = param_grid['batch_size'][0]\n",
    "num_lstm_out = param_grid['hidden_size'][0]\n",
    "optimizer_name = param_grid['optimizer'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ee3c4-36a5-4341-975a-615af2343edd",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f42b01-cf61-4065-a1a0-0158f1f9a654",
   "metadata": {},
   "source": [
    "- 랜덤시드 \n",
    "  - 4444(사랑하는사람이사랑하는사람에게)\n",
    "  - 2514(이세상에서오직하나뿐인사람)\n",
    "  - 4040(사랑사랑)\n",
    "  - 8282(빨리빨리)\n",
    "  - 1004(천사)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7042c4e0-dae0-4533-9e79-ada313ecc451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "randomseedlist=[4444,2514,4040,8282,1004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf442f90-6850-4cee-97f8-642bdf90e5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def final(modelname,train_set, train_label, test_set, test_label,esbnum):\n",
    "    train_loader,valid_loader,test_loader=loaders(train_set, train_label,test_set,test_label,randomseedlist[esbnum])\n",
    "\n",
    "\n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "    criterion = nn.NLLLoss().to(device)\n",
    "    epochs=500\n",
    "    print_every=1000\n",
    "\n",
    "    # 0.001 32 8 Adam\n",
    "    lr = param_grid['lr'][0]\n",
    "    batch_size = param_grid['batch_size'][0]\n",
    "    num_lstm_out = param_grid['hidden_size'][0]\n",
    "    optimizer_name = param_grid['optimizer'][0]\n",
    "\n",
    "    model =modelname.to(device)\n",
    "\n",
    "\n",
    "    # 옵티마이저 설정\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "    #train\n",
    "    steps = 0\n",
    "\n",
    "    for e in tqdm(range(epochs)):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            steps += 1\n",
    "\n",
    "            inputs = inputs.float()\n",
    "            inputs, labels = inputs.to(device),labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # print(inputs.shape)\n",
    "            # print(model.forward(inputs).shape)\n",
    "            output,_ = model.forward(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                model.eval()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    valid_loss, accuracy = validation(model, valid_loader, criterion)\n",
    "\n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.6f}.. \".format(train_loss/print_every),\n",
    "                      \"Val Loss: {:.6f}.. \".format(valid_loss/len(valid_loader)),\n",
    "                      \"Val Accuracy: {:.2f}%\".format(accuracy/len(valid_loader)*100))\n",
    "\n",
    "                # save model if validation loss has decreased\n",
    "                if valid_loss <= valid_loss_min:\n",
    "                    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                    valid_loss_min,\n",
    "                    valid_loss))\n",
    "                    torch.save(model.state_dict(), savepath+ 'malstm_msn_cv_'+str(cv)+'_cond_'+str(cond)+'_esb_'+str(esbnum)+'.pt')\n",
    "                    valid_loss_min = valid_loss\n",
    "\n",
    "                train_loss = 0\n",
    "\n",
    "                model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1376c6-4e46-43aa-8930-24726b1cee99",
   "metadata": {},
   "source": [
    "### ensemble1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb9f4841-b870-422b-8de5-e3a1c3587dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble1 = MLSTMfcn_MSN(num_classes=5, \n",
    "                           num_features=3,\n",
    "                           num_lstm_out=num_lstm_out).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9e0d346-3710-43ce-8b9b-4d85a1b31078",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f0d558228448cfbd4cbb67c9e7407d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/500..  Training Loss: 0.011102..  Val Loss: 0.117180..  Val Accuracy: 95.39%\n",
      "Validation loss decreased (inf --> 36.560029).  Saving model ...\n",
      "Epoch: 3/500..  Training Loss: 0.017092..  Val Loss: 0.399206..  Val Accuracy: 85.73%\n",
      "Epoch: 4/500..  Training Loss: 0.021348..  Val Loss: 0.526220..  Val Accuracy: 82.59%\n",
      "Epoch: 5/500..  Training Loss: 0.024016..  Val Loss: 0.098288..  Val Accuracy: 95.65%\n",
      "Validation loss decreased (36.560029 --> 30.665761).  Saving model ...\n",
      "Epoch: 6/500..  Training Loss: 0.028105..  Val Loss: 0.073268..  Val Accuracy: 96.92%\n",
      "Validation loss decreased (30.665761 --> 22.859638).  Saving model ...\n",
      "Epoch: 7/500..  Training Loss: 0.031609..  Val Loss: 0.067507..  Val Accuracy: 97.17%\n",
      "Validation loss decreased (22.859638 --> 21.062246).  Saving model ...\n",
      "Epoch: 8/500..  Training Loss: 0.033518..  Val Loss: 0.090139..  Val Accuracy: 96.48%\n",
      "Epoch: 9/500..  Training Loss: 0.036061..  Val Loss: 0.068406..  Val Accuracy: 97.12%\n",
      "Epoch: 10/500..  Training Loss: 0.037117..  Val Loss: 0.065970..  Val Accuracy: 97.34%\n",
      "Validation loss decreased (21.062246 --> 20.582636).  Saving model ...\n",
      "Epoch: 11/500..  Training Loss: 0.039005..  Val Loss: 0.091133..  Val Accuracy: 96.35%\n",
      "Epoch: 12/500..  Training Loss: 0.037550..  Val Loss: 0.072779..  Val Accuracy: 97.10%\n",
      "Epoch: 13/500..  Training Loss: 0.038978..  Val Loss: 0.045652..  Val Accuracy: 98.07%\n",
      "Validation loss decreased (20.582636 --> 14.243391).  Saving model ...\n",
      "Epoch: 14/500..  Training Loss: 0.041768..  Val Loss: 0.071114..  Val Accuracy: 97.36%\n",
      "Epoch: 15/500..  Training Loss: 0.039955..  Val Loss: 0.083810..  Val Accuracy: 96.64%\n",
      "Epoch: 17/500..  Training Loss: 0.000250..  Val Loss: 0.101995..  Val Accuracy: 96.20%\n",
      "Epoch: 18/500..  Training Loss: 0.002864..  Val Loss: 0.039966..  Val Accuracy: 98.50%\n",
      "Validation loss decreased (14.243391 --> 12.469439).  Saving model ...\n",
      "Epoch: 19/500..  Training Loss: 0.004429..  Val Loss: 0.040270..  Val Accuracy: 98.25%\n",
      "Epoch: 20/500..  Training Loss: 0.007049..  Val Loss: 0.034790..  Val Accuracy: 98.59%\n",
      "Validation loss decreased (12.469439 --> 10.854580).  Saving model ...\n",
      "Epoch: 21/500..  Training Loss: 0.008834..  Val Loss: 0.031709..  Val Accuracy: 98.78%\n",
      "Validation loss decreased (10.854580 --> 9.893186).  Saving model ...\n",
      "Epoch: 22/500..  Training Loss: 0.012481..  Val Loss: 0.035844..  Val Accuracy: 98.60%\n",
      "Epoch: 23/500..  Training Loss: 0.011714..  Val Loss: 0.029317..  Val Accuracy: 98.88%\n",
      "Validation loss decreased (9.893186 --> 9.146901).  Saving model ...\n",
      "Epoch: 24/500..  Training Loss: 0.013456..  Val Loss: 0.218866..  Val Accuracy: 93.42%\n",
      "Epoch: 25/500..  Training Loss: 0.014335..  Val Loss: 0.039617..  Val Accuracy: 98.38%\n",
      "Epoch: 26/500..  Training Loss: 0.016103..  Val Loss: 0.039875..  Val Accuracy: 98.42%\n",
      "Epoch: 27/500..  Training Loss: 0.018240..  Val Loss: 0.034324..  Val Accuracy: 98.53%\n",
      "Epoch: 28/500..  Training Loss: 0.017708..  Val Loss: 0.024707..  Val Accuracy: 99.03%\n",
      "Validation loss decreased (9.146901 --> 7.708505).  Saving model ...\n",
      "Epoch: 29/500..  Training Loss: 0.019596..  Val Loss: 0.037109..  Val Accuracy: 98.54%\n",
      "Epoch: 30/500..  Training Loss: 0.020987..  Val Loss: 0.028276..  Val Accuracy: 99.05%\n",
      "Epoch: 31/500..  Training Loss: 0.022135..  Val Loss: 0.030626..  Val Accuracy: 98.82%\n",
      "Epoch: 33/500..  Training Loss: 0.000353..  Val Loss: 0.023192..  Val Accuracy: 99.09%\n",
      "Validation loss decreased (7.708505 --> 7.236003).  Saving model ...\n",
      "Epoch: 34/500..  Training Loss: 0.001924..  Val Loss: 0.039188..  Val Accuracy: 98.57%\n",
      "Epoch: 35/500..  Training Loss: 0.002551..  Val Loss: 0.044144..  Val Accuracy: 98.45%\n",
      "Epoch: 36/500..  Training Loss: 0.003802..  Val Loss: 0.029273..  Val Accuracy: 98.88%\n",
      "Epoch: 37/500..  Training Loss: 0.005179..  Val Loss: 0.063241..  Val Accuracy: 97.78%\n",
      "Epoch: 38/500..  Training Loss: 0.006522..  Val Loss: 0.019502..  Val Accuracy: 99.29%\n",
      "Validation loss decreased (7.236003 --> 6.084641).  Saving model ...\n",
      "Epoch: 39/500..  Training Loss: 0.007030..  Val Loss: 0.027151..  Val Accuracy: 99.05%\n",
      "Epoch: 40/500..  Training Loss: 0.007893..  Val Loss: 0.021858..  Val Accuracy: 99.03%\n",
      "Epoch: 41/500..  Training Loss: 0.011136..  Val Loss: 0.023823..  Val Accuracy: 99.10%\n",
      "Epoch: 42/500..  Training Loss: 0.010694..  Val Loss: 0.020062..  Val Accuracy: 99.23%\n",
      "Epoch: 43/500..  Training Loss: 0.010197..  Val Loss: 0.027181..  Val Accuracy: 98.95%\n",
      "Epoch: 44/500..  Training Loss: 0.013809..  Val Loss: 0.046442..  Val Accuracy: 98.43%\n",
      "Epoch: 45/500..  Training Loss: 0.012306..  Val Loss: 0.028339..  Val Accuracy: 98.87%\n",
      "Epoch: 46/500..  Training Loss: 0.014928..  Val Loss: 0.026712..  Val Accuracy: 98.91%\n",
      "Epoch: 47/500..  Training Loss: 0.015695..  Val Loss: 0.033054..  Val Accuracy: 98.86%\n",
      "Epoch: 49/500..  Training Loss: 0.000108..  Val Loss: 0.021765..  Val Accuracy: 99.22%\n",
      "Epoch: 50/500..  Training Loss: 0.001733..  Val Loss: 0.025549..  Val Accuracy: 99.00%\n",
      "Epoch: 51/500..  Training Loss: 0.002545..  Val Loss: 0.027080..  Val Accuracy: 99.00%\n",
      "Epoch: 52/500..  Training Loss: 0.003472..  Val Loss: 0.021309..  Val Accuracy: 99.21%\n",
      "Epoch: 53/500..  Training Loss: 0.005129..  Val Loss: 0.029496..  Val Accuracy: 98.94%\n",
      "Epoch: 54/500..  Training Loss: 0.005023..  Val Loss: 0.020867..  Val Accuracy: 99.28%\n",
      "Epoch: 55/500..  Training Loss: 0.004751..  Val Loss: 0.020946..  Val Accuracy: 99.18%\n",
      "Epoch: 56/500..  Training Loss: 0.005871..  Val Loss: 0.017045..  Val Accuracy: 99.32%\n",
      "Validation loss decreased (6.084641 --> 5.318030).  Saving model ...\n",
      "Epoch: 57/500..  Training Loss: 0.008285..  Val Loss: 0.019840..  Val Accuracy: 99.15%\n",
      "Epoch: 58/500..  Training Loss: 0.008196..  Val Loss: 0.028596..  Val Accuracy: 99.02%\n",
      "Epoch: 59/500..  Training Loss: 0.007922..  Val Loss: 0.031774..  Val Accuracy: 98.89%\n",
      "Epoch: 60/500..  Training Loss: 0.011338..  Val Loss: 0.029084..  Val Accuracy: 98.95%\n",
      "Epoch: 61/500..  Training Loss: 0.011044..  Val Loss: 0.035201..  Val Accuracy: 98.70%\n",
      "Epoch: 62/500..  Training Loss: 0.012484..  Val Loss: 0.030451..  Val Accuracy: 98.93%\n",
      "Epoch: 63/500..  Training Loss: 0.012017..  Val Loss: 0.023912..  Val Accuracy: 99.06%\n",
      "Epoch: 65/500..  Training Loss: 0.000424..  Val Loss: 0.030680..  Val Accuracy: 98.91%\n",
      "Epoch: 66/500..  Training Loss: 0.001100..  Val Loss: 0.043214..  Val Accuracy: 98.72%\n",
      "Epoch: 67/500..  Training Loss: 0.002991..  Val Loss: 0.022384..  Val Accuracy: 99.21%\n",
      "Epoch: 68/500..  Training Loss: 0.003677..  Val Loss: 0.021169..  Val Accuracy: 99.23%\n",
      "Epoch: 69/500..  Training Loss: 0.003086..  Val Loss: 0.032175..  Val Accuracy: 98.95%\n",
      "Epoch: 70/500..  Training Loss: 0.003426..  Val Loss: 0.021941..  Val Accuracy: 99.25%\n",
      "Epoch: 71/500..  Training Loss: 0.004883..  Val Loss: 0.017951..  Val Accuracy: 99.24%\n",
      "Epoch: 72/500..  Training Loss: 0.005534..  Val Loss: 0.019480..  Val Accuracy: 99.30%\n",
      "Epoch: 73/500..  Training Loss: 0.006462..  Val Loss: 0.022525..  Val Accuracy: 99.19%\n",
      "Epoch: 74/500..  Training Loss: 0.008835..  Val Loss: 0.025106..  Val Accuracy: 99.18%\n",
      "Epoch: 75/500..  Training Loss: 0.007468..  Val Loss: 0.029732..  Val Accuracy: 99.13%\n",
      "Epoch: 76/500..  Training Loss: 0.008998..  Val Loss: 0.021941..  Val Accuracy: 99.15%\n",
      "Epoch: 77/500..  Training Loss: 0.009186..  Val Loss: 0.038678..  Val Accuracy: 98.88%\n",
      "Epoch: 78/500..  Training Loss: 0.010093..  Val Loss: 0.036085..  Val Accuracy: 98.82%\n",
      "Epoch: 79/500..  Training Loss: 0.010781..  Val Loss: 0.020698..  Val Accuracy: 99.34%\n",
      "Epoch: 81/500..  Training Loss: 0.000418..  Val Loss: 0.019349..  Val Accuracy: 99.38%\n",
      "Epoch: 82/500..  Training Loss: 0.000999..  Val Loss: 0.018955..  Val Accuracy: 99.27%\n",
      "Epoch: 83/500..  Training Loss: 0.001577..  Val Loss: 0.019563..  Val Accuracy: 99.29%\n",
      "Epoch: 84/500..  Training Loss: 0.002872..  Val Loss: 0.020374..  Val Accuracy: 99.30%\n",
      "Epoch: 85/500..  Training Loss: 0.003419..  Val Loss: 0.046515..  Val Accuracy: 98.69%\n",
      "Epoch: 86/500..  Training Loss: 0.004131..  Val Loss: 0.018008..  Val Accuracy: 99.30%\n",
      "Epoch: 87/500..  Training Loss: 0.005551..  Val Loss: 0.025848..  Val Accuracy: 99.27%\n",
      "Epoch: 88/500..  Training Loss: 0.004620..  Val Loss: 0.020301..  Val Accuracy: 99.28%\n",
      "Epoch: 89/500..  Training Loss: 0.006253..  Val Loss: 0.018275..  Val Accuracy: 99.22%\n",
      "Epoch: 90/500..  Training Loss: 0.006316..  Val Loss: 0.027076..  Val Accuracy: 99.19%\n",
      "Epoch: 91/500..  Training Loss: 0.006367..  Val Loss: 0.023185..  Val Accuracy: 99.14%\n",
      "Epoch: 92/500..  Training Loss: 0.007047..  Val Loss: 0.017753..  Val Accuracy: 99.27%\n",
      "Epoch: 93/500..  Training Loss: 0.008172..  Val Loss: 0.019142..  Val Accuracy: 99.36%\n",
      "Epoch: 94/500..  Training Loss: 0.009515..  Val Loss: 0.021492..  Val Accuracy: 99.19%\n",
      "Epoch: 95/500..  Training Loss: 0.009608..  Val Loss: 0.021340..  Val Accuracy: 99.20%\n",
      "Epoch: 97/500..  Training Loss: 0.000402..  Val Loss: 0.020912..  Val Accuracy: 99.16%\n",
      "Epoch: 98/500..  Training Loss: 0.001030..  Val Loss: 0.025419..  Val Accuracy: 99.14%\n",
      "Epoch: 99/500..  Training Loss: 0.002308..  Val Loss: 0.021225..  Val Accuracy: 99.22%\n",
      "Epoch: 100/500..  Training Loss: 0.001618..  Val Loss: 0.017131..  Val Accuracy: 99.32%\n",
      "Epoch: 101/500..  Training Loss: 0.002807..  Val Loss: 0.017197..  Val Accuracy: 99.34%\n",
      "Epoch: 102/500..  Training Loss: 0.003624..  Val Loss: 0.020207..  Val Accuracy: 99.33%\n",
      "Epoch: 103/500..  Training Loss: 0.004200..  Val Loss: 0.022537..  Val Accuracy: 99.20%\n",
      "Epoch: 104/500..  Training Loss: 0.004798..  Val Loss: 0.016683..  Val Accuracy: 99.35%\n",
      "Validation loss decreased (5.318030 --> 5.204949).  Saving model ...\n",
      "Epoch: 105/500..  Training Loss: 0.004958..  Val Loss: 0.018656..  Val Accuracy: 99.31%\n",
      "Epoch: 106/500..  Training Loss: 0.005453..  Val Loss: 0.021923..  Val Accuracy: 99.31%\n",
      "Epoch: 107/500..  Training Loss: 0.005750..  Val Loss: 0.023056..  Val Accuracy: 99.29%\n",
      "Epoch: 108/500..  Training Loss: 0.006501..  Val Loss: 0.020654..  Val Accuracy: 99.32%\n",
      "Epoch: 109/500..  Training Loss: 0.007606..  Val Loss: 0.018626..  Val Accuracy: 99.41%\n",
      "Epoch: 110/500..  Training Loss: 0.007123..  Val Loss: 0.018208..  Val Accuracy: 99.47%\n",
      "Epoch: 111/500..  Training Loss: 0.008017..  Val Loss: 0.016356..  Val Accuracy: 99.40%\n",
      "Validation loss decreased (5.204949 --> 5.103019).  Saving model ...\n",
      "Epoch: 113/500..  Training Loss: 0.000563..  Val Loss: 0.015062..  Val Accuracy: 99.45%\n",
      "Validation loss decreased (5.103019 --> 4.699464).  Saving model ...\n",
      "Epoch: 114/500..  Training Loss: 0.000801..  Val Loss: 0.022544..  Val Accuracy: 99.30%\n",
      "Epoch: 115/500..  Training Loss: 0.001701..  Val Loss: 0.015466..  Val Accuracy: 99.36%\n",
      "Epoch: 116/500..  Training Loss: 0.002382..  Val Loss: 0.022008..  Val Accuracy: 99.31%\n",
      "Epoch: 117/500..  Training Loss: 0.003104..  Val Loss: 0.023103..  Val Accuracy: 99.31%\n",
      "Epoch: 118/500..  Training Loss: 0.002895..  Val Loss: 0.015715..  Val Accuracy: 99.44%\n",
      "Epoch: 119/500..  Training Loss: 0.003839..  Val Loss: 0.029769..  Val Accuracy: 99.04%\n",
      "Epoch: 120/500..  Training Loss: 0.004959..  Val Loss: 0.021758..  Val Accuracy: 99.25%\n",
      "Epoch: 121/500..  Training Loss: 0.004240..  Val Loss: 0.018956..  Val Accuracy: 99.37%\n",
      "Epoch: 122/500..  Training Loss: 0.005042..  Val Loss: 0.020912..  Val Accuracy: 99.27%\n",
      "Epoch: 123/500..  Training Loss: 0.005245..  Val Loss: 0.019214..  Val Accuracy: 99.30%\n",
      "Epoch: 124/500..  Training Loss: 0.006040..  Val Loss: 0.020440..  Val Accuracy: 99.41%\n",
      "Epoch: 125/500..  Training Loss: 0.006724..  Val Loss: 0.024611..  Val Accuracy: 99.29%\n",
      "Epoch: 126/500..  Training Loss: 0.005948..  Val Loss: 0.022922..  Val Accuracy: 99.23%\n",
      "Epoch: 128/500..  Training Loss: 0.000000..  Val Loss: 0.025438..  Val Accuracy: 99.17%\n",
      "Epoch: 129/500..  Training Loss: 0.000349..  Val Loss: 0.021379..  Val Accuracy: 99.25%\n",
      "Epoch: 130/500..  Training Loss: 0.000911..  Val Loss: 0.018108..  Val Accuracy: 99.34%\n",
      "Epoch: 131/500..  Training Loss: 0.001984..  Val Loss: 0.045226..  Val Accuracy: 98.68%\n",
      "Epoch: 132/500..  Training Loss: 0.001381..  Val Loss: 0.020165..  Val Accuracy: 99.39%\n",
      "Epoch: 133/500..  Training Loss: 0.002042..  Val Loss: 0.022680..  Val Accuracy: 99.25%\n",
      "Epoch: 134/500..  Training Loss: 0.002820..  Val Loss: 0.015150..  Val Accuracy: 99.46%\n",
      "Epoch: 135/500..  Training Loss: 0.003567..  Val Loss: 0.018838..  Val Accuracy: 99.29%\n",
      "Epoch: 136/500..  Training Loss: 0.002684..  Val Loss: 0.022200..  Val Accuracy: 99.35%\n",
      "Epoch: 137/500..  Training Loss: 0.004052..  Val Loss: 0.025377..  Val Accuracy: 99.11%\n",
      "Epoch: 138/500..  Training Loss: 0.003657..  Val Loss: 0.019009..  Val Accuracy: 99.31%\n",
      "Epoch: 139/500..  Training Loss: 0.004707..  Val Loss: 0.017464..  Val Accuracy: 99.41%\n",
      "Epoch: 140/500..  Training Loss: 0.006200..  Val Loss: 0.019561..  Val Accuracy: 99.34%\n",
      "Epoch: 141/500..  Training Loss: 0.006009..  Val Loss: 0.018996..  Val Accuracy: 99.35%\n",
      "Epoch: 142/500..  Training Loss: 0.004867..  Val Loss: 0.022883..  Val Accuracy: 99.30%\n",
      "Epoch: 144/500..  Training Loss: 0.000082..  Val Loss: 0.017899..  Val Accuracy: 99.40%\n",
      "Epoch: 145/500..  Training Loss: 0.000612..  Val Loss: 0.019107..  Val Accuracy: 99.36%\n",
      "Epoch: 146/500..  Training Loss: 0.001008..  Val Loss: 0.022820..  Val Accuracy: 99.27%\n",
      "Epoch: 147/500..  Training Loss: 0.001277..  Val Loss: 0.021996..  Val Accuracy: 99.30%\n",
      "Epoch: 148/500..  Training Loss: 0.000906..  Val Loss: 0.017667..  Val Accuracy: 99.45%\n",
      "Epoch: 149/500..  Training Loss: 0.001913..  Val Loss: 0.016041..  Val Accuracy: 99.50%\n",
      "Epoch: 150/500..  Training Loss: 0.003308..  Val Loss: 0.020673..  Val Accuracy: 99.21%\n",
      "Epoch: 151/500..  Training Loss: 0.003192..  Val Loss: 0.027869..  Val Accuracy: 99.09%\n",
      "Epoch: 152/500..  Training Loss: 0.002665..  Val Loss: 0.014997..  Val Accuracy: 99.46%\n",
      "Validation loss decreased (4.699464 --> 4.678967).  Saving model ...\n",
      "Epoch: 153/500..  Training Loss: 0.003824..  Val Loss: 0.015546..  Val Accuracy: 99.41%\n",
      "Epoch: 154/500..  Training Loss: 0.004128..  Val Loss: 0.020256..  Val Accuracy: 99.33%\n",
      "Epoch: 155/500..  Training Loss: 0.004867..  Val Loss: 0.014561..  Val Accuracy: 99.52%\n",
      "Validation loss decreased (4.678967 --> 4.543003).  Saving model ...\n",
      "Epoch: 156/500..  Training Loss: 0.004294..  Val Loss: 0.016383..  Val Accuracy: 99.52%\n",
      "Epoch: 157/500..  Training Loss: 0.006147..  Val Loss: 0.014540..  Val Accuracy: 99.51%\n",
      "Validation loss decreased (4.543003 --> 4.536497).  Saving model ...\n",
      "Epoch: 158/500..  Training Loss: 0.007029..  Val Loss: 0.017499..  Val Accuracy: 99.40%\n",
      "Epoch: 160/500..  Training Loss: 0.000278..  Val Loss: 0.020310..  Val Accuracy: 99.38%\n",
      "Epoch: 161/500..  Training Loss: 0.000819..  Val Loss: 0.022538..  Val Accuracy: 99.18%\n",
      "Epoch: 162/500..  Training Loss: 0.000845..  Val Loss: 0.017157..  Val Accuracy: 99.44%\n",
      "Epoch: 163/500..  Training Loss: 0.001345..  Val Loss: 0.018264..  Val Accuracy: 99.38%\n",
      "Epoch: 164/500..  Training Loss: 0.001972..  Val Loss: 0.017794..  Val Accuracy: 99.35%\n",
      "Epoch: 165/500..  Training Loss: 0.002085..  Val Loss: 0.019746..  Val Accuracy: 99.42%\n",
      "Epoch: 166/500..  Training Loss: 0.002167..  Val Loss: 0.030638..  Val Accuracy: 99.15%\n",
      "Epoch: 167/500..  Training Loss: 0.001764..  Val Loss: 0.018311..  Val Accuracy: 99.46%\n",
      "Epoch: 168/500..  Training Loss: 0.002448..  Val Loss: 0.015874..  Val Accuracy: 99.53%\n",
      "Epoch: 169/500..  Training Loss: 0.003652..  Val Loss: 0.015331..  Val Accuracy: 99.47%\n",
      "Epoch: 170/500..  Training Loss: 0.002882..  Val Loss: 0.025726..  Val Accuracy: 99.18%\n",
      "Epoch: 171/500..  Training Loss: 0.003241..  Val Loss: 0.016233..  Val Accuracy: 99.42%\n",
      "Epoch: 172/500..  Training Loss: 0.004775..  Val Loss: 0.015362..  Val Accuracy: 99.43%\n",
      "Epoch: 173/500..  Training Loss: 0.004036..  Val Loss: 0.017637..  Val Accuracy: 99.44%\n",
      "Epoch: 174/500..  Training Loss: 0.005401..  Val Loss: 0.017517..  Val Accuracy: 99.42%\n",
      "Epoch: 176/500..  Training Loss: 0.000101..  Val Loss: 0.022607..  Val Accuracy: 99.19%\n",
      "Epoch: 177/500..  Training Loss: 0.000207..  Val Loss: 0.018287..  Val Accuracy: 99.43%\n",
      "Epoch: 178/500..  Training Loss: 0.000616..  Val Loss: 0.023354..  Val Accuracy: 99.30%\n",
      "Epoch: 179/500..  Training Loss: 0.001241..  Val Loss: 0.018511..  Val Accuracy: 99.42%\n",
      "Epoch: 180/500..  Training Loss: 0.001041..  Val Loss: 0.017156..  Val Accuracy: 99.38%\n",
      "Epoch: 181/500..  Training Loss: 0.001233..  Val Loss: 0.023022..  Val Accuracy: 99.37%\n",
      "Epoch: 182/500..  Training Loss: 0.002111..  Val Loss: 0.018915..  Val Accuracy: 99.36%\n",
      "Epoch: 183/500..  Training Loss: 0.001574..  Val Loss: 0.016535..  Val Accuracy: 99.45%\n",
      "Epoch: 184/500..  Training Loss: 0.003709..  Val Loss: 0.023460..  Val Accuracy: 99.28%\n",
      "Epoch: 185/500..  Training Loss: 0.002889..  Val Loss: 0.016079..  Val Accuracy: 99.56%\n",
      "Epoch: 186/500..  Training Loss: 0.003389..  Val Loss: 0.017333..  Val Accuracy: 99.44%\n",
      "Epoch: 187/500..  Training Loss: 0.003201..  Val Loss: 0.025385..  Val Accuracy: 99.16%\n",
      "Epoch: 188/500..  Training Loss: 0.005445..  Val Loss: 0.023480..  Val Accuracy: 99.29%\n",
      "Epoch: 189/500..  Training Loss: 0.002739..  Val Loss: 0.018024..  Val Accuracy: 99.47%\n",
      "Epoch: 190/500..  Training Loss: 0.004324..  Val Loss: 0.021204..  Val Accuracy: 99.39%\n",
      "Epoch: 192/500..  Training Loss: 0.000116..  Val Loss: 0.034030..  Val Accuracy: 99.13%\n",
      "Epoch: 193/500..  Training Loss: 0.000238..  Val Loss: 0.023293..  Val Accuracy: 99.39%\n",
      "Epoch: 194/500..  Training Loss: 0.000777..  Val Loss: 0.016819..  Val Accuracy: 99.47%\n",
      "Epoch: 195/500..  Training Loss: 0.001033..  Val Loss: 0.023040..  Val Accuracy: 99.44%\n",
      "Epoch: 196/500..  Training Loss: 0.001468..  Val Loss: 0.021996..  Val Accuracy: 99.34%\n",
      "Epoch: 197/500..  Training Loss: 0.002207..  Val Loss: 0.024203..  Val Accuracy: 99.38%\n",
      "Epoch: 198/500..  Training Loss: 0.002045..  Val Loss: 0.023831..  Val Accuracy: 99.33%\n",
      "Epoch: 199/500..  Training Loss: 0.002029..  Val Loss: 0.017399..  Val Accuracy: 99.43%\n",
      "Epoch: 200/500..  Training Loss: 0.002040..  Val Loss: 0.025929..  Val Accuracy: 99.37%\n",
      "Epoch: 201/500..  Training Loss: 0.004321..  Val Loss: 0.016239..  Val Accuracy: 99.48%\n",
      "Epoch: 202/500..  Training Loss: 0.002509..  Val Loss: 0.015070..  Val Accuracy: 99.59%\n",
      "Epoch: 203/500..  Training Loss: 0.003572..  Val Loss: 0.016653..  Val Accuracy: 99.45%\n",
      "Epoch: 204/500..  Training Loss: 0.002276..  Val Loss: 0.019310..  Val Accuracy: 99.35%\n",
      "Epoch: 205/500..  Training Loss: 0.004572..  Val Loss: 0.014223..  Val Accuracy: 99.55%\n",
      "Validation loss decreased (4.536497 --> 4.437457).  Saving model ...\n",
      "Epoch: 206/500..  Training Loss: 0.004947..  Val Loss: 0.018917..  Val Accuracy: 99.47%\n",
      "Epoch: 208/500..  Training Loss: 0.000160..  Val Loss: 0.017488..  Val Accuracy: 99.53%\n",
      "Epoch: 209/500..  Training Loss: 0.001241..  Val Loss: 0.017625..  Val Accuracy: 99.40%\n",
      "Epoch: 210/500..  Training Loss: 0.000364..  Val Loss: 0.019261..  Val Accuracy: 99.49%\n",
      "Epoch: 211/500..  Training Loss: 0.001173..  Val Loss: 0.025184..  Val Accuracy: 99.23%\n",
      "Epoch: 212/500..  Training Loss: 0.001011..  Val Loss: 0.016891..  Val Accuracy: 99.49%\n",
      "Epoch: 213/500..  Training Loss: 0.002160..  Val Loss: 0.016749..  Val Accuracy: 99.51%\n",
      "Epoch: 214/500..  Training Loss: 0.002176..  Val Loss: 0.018723..  Val Accuracy: 99.44%\n",
      "Epoch: 215/500..  Training Loss: 0.001321..  Val Loss: 0.026900..  Val Accuracy: 99.35%\n",
      "Epoch: 216/500..  Training Loss: 0.002188..  Val Loss: 0.021819..  Val Accuracy: 99.36%\n",
      "Epoch: 217/500..  Training Loss: 0.002635..  Val Loss: 0.016795..  Val Accuracy: 99.48%\n",
      "Epoch: 218/500..  Training Loss: 0.002812..  Val Loss: 0.018617..  Val Accuracy: 99.43%\n",
      "Epoch: 219/500..  Training Loss: 0.003900..  Val Loss: 0.019862..  Val Accuracy: 99.37%\n",
      "Epoch: 220/500..  Training Loss: 0.003537..  Val Loss: 0.016032..  Val Accuracy: 99.52%\n",
      "Epoch: 221/500..  Training Loss: 0.004834..  Val Loss: 0.016020..  Val Accuracy: 99.47%\n",
      "Epoch: 222/500..  Training Loss: 0.003928..  Val Loss: 0.016199..  Val Accuracy: 99.45%\n",
      "Epoch: 224/500..  Training Loss: 0.000107..  Val Loss: 0.018598..  Val Accuracy: 99.41%\n",
      "Epoch: 225/500..  Training Loss: 0.000562..  Val Loss: 0.018064..  Val Accuracy: 99.42%\n",
      "Epoch: 226/500..  Training Loss: 0.000866..  Val Loss: 0.016020..  Val Accuracy: 99.57%\n",
      "Epoch: 227/500..  Training Loss: 0.000969..  Val Loss: 0.016704..  Val Accuracy: 99.50%\n",
      "Epoch: 228/500..  Training Loss: 0.001207..  Val Loss: 0.015566..  Val Accuracy: 99.52%\n",
      "Epoch: 229/500..  Training Loss: 0.001873..  Val Loss: 0.017230..  Val Accuracy: 99.57%\n",
      "Epoch: 230/500..  Training Loss: 0.000961..  Val Loss: 0.017470..  Val Accuracy: 99.52%\n",
      "Epoch: 231/500..  Training Loss: 0.003131..  Val Loss: 0.024046..  Val Accuracy: 99.40%\n",
      "Epoch: 232/500..  Training Loss: 0.002668..  Val Loss: 0.016051..  Val Accuracy: 99.47%\n",
      "Epoch: 233/500..  Training Loss: 0.002486..  Val Loss: 0.014897..  Val Accuracy: 99.51%\n",
      "Epoch: 234/500..  Training Loss: 0.002822..  Val Loss: 0.016724..  Val Accuracy: 99.48%\n",
      "Epoch: 235/500..  Training Loss: 0.003113..  Val Loss: 0.015785..  Val Accuracy: 99.51%\n",
      "Epoch: 236/500..  Training Loss: 0.002280..  Val Loss: 0.017095..  Val Accuracy: 99.45%\n",
      "Epoch: 237/500..  Training Loss: 0.003746..  Val Loss: 0.022772..  Val Accuracy: 99.28%\n",
      "Epoch: 238/500..  Training Loss: 0.004163..  Val Loss: 0.017174..  Val Accuracy: 99.42%\n",
      "Epoch: 240/500..  Training Loss: 0.000329..  Val Loss: 0.017466..  Val Accuracy: 99.50%\n",
      "Epoch: 241/500..  Training Loss: 0.000403..  Val Loss: 0.017697..  Val Accuracy: 99.39%\n",
      "Epoch: 242/500..  Training Loss: 0.000433..  Val Loss: 0.018683..  Val Accuracy: 99.38%\n",
      "Epoch: 243/500..  Training Loss: 0.000592..  Val Loss: 0.018914..  Val Accuracy: 99.41%\n",
      "Epoch: 244/500..  Training Loss: 0.001712..  Val Loss: 0.019039..  Val Accuracy: 99.41%\n",
      "Epoch: 245/500..  Training Loss: 0.002051..  Val Loss: 0.019459..  Val Accuracy: 99.34%\n",
      "Epoch: 246/500..  Training Loss: 0.001982..  Val Loss: 0.018251..  Val Accuracy: 99.34%\n",
      "Epoch: 247/500..  Training Loss: 0.001665..  Val Loss: 0.017679..  Val Accuracy: 99.53%\n",
      "Epoch: 248/500..  Training Loss: 0.002136..  Val Loss: 0.021022..  Val Accuracy: 99.37%\n",
      "Epoch: 249/500..  Training Loss: 0.002315..  Val Loss: 0.017229..  Val Accuracy: 99.47%\n",
      "Epoch: 250/500..  Training Loss: 0.003339..  Val Loss: 0.014275..  Val Accuracy: 99.59%\n",
      "Epoch: 251/500..  Training Loss: 0.002867..  Val Loss: 0.015324..  Val Accuracy: 99.59%\n",
      "Epoch: 252/500..  Training Loss: 0.003396..  Val Loss: 0.016496..  Val Accuracy: 99.52%\n",
      "Epoch: 253/500..  Training Loss: 0.003491..  Val Loss: 0.018804..  Val Accuracy: 99.56%\n",
      "Epoch: 255/500..  Training Loss: 0.000002..  Val Loss: 0.017307..  Val Accuracy: 99.46%\n",
      "Epoch: 256/500..  Training Loss: 0.000379..  Val Loss: 0.018241..  Val Accuracy: 99.39%\n",
      "Epoch: 257/500..  Training Loss: 0.000341..  Val Loss: 0.018487..  Val Accuracy: 99.45%\n",
      "Epoch: 258/500..  Training Loss: 0.000418..  Val Loss: 0.022823..  Val Accuracy: 99.38%\n",
      "Epoch: 259/500..  Training Loss: 0.001374..  Val Loss: 0.021153..  Val Accuracy: 99.40%\n",
      "Epoch: 260/500..  Training Loss: 0.001236..  Val Loss: 0.020164..  Val Accuracy: 99.42%\n",
      "Epoch: 261/500..  Training Loss: 0.001071..  Val Loss: 0.015481..  Val Accuracy: 99.55%\n",
      "Epoch: 262/500..  Training Loss: 0.002440..  Val Loss: 0.017678..  Val Accuracy: 99.43%\n",
      "Epoch: 263/500..  Training Loss: 0.001446..  Val Loss: 0.016833..  Val Accuracy: 99.55%\n",
      "Epoch: 264/500..  Training Loss: 0.001864..  Val Loss: 0.020533..  Val Accuracy: 99.40%\n",
      "Epoch: 265/500..  Training Loss: 0.002454..  Val Loss: 0.025525..  Val Accuracy: 99.28%\n",
      "Epoch: 266/500..  Training Loss: 0.002684..  Val Loss: 0.021515..  Val Accuracy: 99.41%\n",
      "Epoch: 267/500..  Training Loss: 0.003432..  Val Loss: 0.017485..  Val Accuracy: 99.44%\n",
      "Epoch: 268/500..  Training Loss: 0.003498..  Val Loss: 0.031798..  Val Accuracy: 99.17%\n",
      "Epoch: 269/500..  Training Loss: 0.002647..  Val Loss: 0.017657..  Val Accuracy: 99.49%\n",
      "Epoch: 271/500..  Training Loss: 0.000110..  Val Loss: 0.026049..  Val Accuracy: 99.25%\n",
      "Epoch: 272/500..  Training Loss: 0.000207..  Val Loss: 0.015944..  Val Accuracy: 99.42%\n",
      "Epoch: 273/500..  Training Loss: 0.000306..  Val Loss: 0.018127..  Val Accuracy: 99.50%\n",
      "Epoch: 274/500..  Training Loss: 0.001346..  Val Loss: 0.026064..  Val Accuracy: 99.26%\n",
      "Epoch: 275/500..  Training Loss: 0.000599..  Val Loss: 0.015542..  Val Accuracy: 99.53%\n",
      "Epoch: 276/500..  Training Loss: 0.001550..  Val Loss: 0.017641..  Val Accuracy: 99.50%\n",
      "Epoch: 277/500..  Training Loss: 0.001365..  Val Loss: 0.017657..  Val Accuracy: 99.46%\n",
      "Epoch: 278/500..  Training Loss: 0.000904..  Val Loss: 0.021533..  Val Accuracy: 99.39%\n",
      "Epoch: 279/500..  Training Loss: 0.002358..  Val Loss: 0.017695..  Val Accuracy: 99.42%\n",
      "Epoch: 280/500..  Training Loss: 0.001508..  Val Loss: 0.019202..  Val Accuracy: 99.46%\n",
      "Epoch: 281/500..  Training Loss: 0.002536..  Val Loss: 0.016393..  Val Accuracy: 99.49%\n",
      "Epoch: 282/500..  Training Loss: 0.002837..  Val Loss: 0.018725..  Val Accuracy: 99.48%\n",
      "Epoch: 283/500..  Training Loss: 0.002036..  Val Loss: 0.014408..  Val Accuracy: 99.58%\n",
      "Epoch: 284/500..  Training Loss: 0.003832..  Val Loss: 0.023648..  Val Accuracy: 99.34%\n",
      "Epoch: 285/500..  Training Loss: 0.003986..  Val Loss: 0.019486..  Val Accuracy: 99.49%\n",
      "Epoch: 287/500..  Training Loss: 0.000032..  Val Loss: 0.016263..  Val Accuracy: 99.51%\n",
      "Epoch: 288/500..  Training Loss: 0.000108..  Val Loss: 0.016162..  Val Accuracy: 99.54%\n",
      "Epoch: 289/500..  Training Loss: 0.000560..  Val Loss: 0.065014..  Val Accuracy: 98.86%\n",
      "Epoch: 290/500..  Training Loss: 0.001274..  Val Loss: 0.021996..  Val Accuracy: 99.36%\n",
      "Epoch: 291/500..  Training Loss: 0.001272..  Val Loss: 0.025546..  Val Accuracy: 99.29%\n",
      "Epoch: 292/500..  Training Loss: 0.001348..  Val Loss: 0.023153..  Val Accuracy: 99.27%\n",
      "Epoch: 293/500..  Training Loss: 0.001082..  Val Loss: 0.021171..  Val Accuracy: 99.44%\n",
      "Epoch: 294/500..  Training Loss: 0.000856..  Val Loss: 0.019938..  Val Accuracy: 99.49%\n",
      "Epoch: 295/500..  Training Loss: 0.001697..  Val Loss: 0.018893..  Val Accuracy: 99.52%\n",
      "Epoch: 296/500..  Training Loss: 0.002081..  Val Loss: 0.015008..  Val Accuracy: 99.57%\n",
      "Epoch: 297/500..  Training Loss: 0.003823..  Val Loss: 0.019773..  Val Accuracy: 99.38%\n",
      "Epoch: 298/500..  Training Loss: 0.002892..  Val Loss: 0.019058..  Val Accuracy: 99.40%\n",
      "Epoch: 299/500..  Training Loss: 0.002369..  Val Loss: 0.020349..  Val Accuracy: 99.46%\n",
      "Epoch: 300/500..  Training Loss: 0.003918..  Val Loss: 0.016011..  Val Accuracy: 99.60%\n",
      "Epoch: 301/500..  Training Loss: 0.002427..  Val Loss: 0.021109..  Val Accuracy: 99.33%\n",
      "Epoch: 303/500..  Training Loss: 0.000123..  Val Loss: 0.017315..  Val Accuracy: 99.41%\n",
      "Epoch: 304/500..  Training Loss: 0.000245..  Val Loss: 0.017717..  Val Accuracy: 99.47%\n",
      "Epoch: 305/500..  Training Loss: 0.000238..  Val Loss: 0.018621..  Val Accuracy: 99.47%\n",
      "Epoch: 306/500..  Training Loss: 0.000886..  Val Loss: 0.019432..  Val Accuracy: 99.42%\n",
      "Epoch: 307/500..  Training Loss: 0.000837..  Val Loss: 0.019180..  Val Accuracy: 99.45%\n",
      "Epoch: 308/500..  Training Loss: 0.001529..  Val Loss: 0.018127..  Val Accuracy: 99.50%\n",
      "Epoch: 309/500..  Training Loss: 0.001102..  Val Loss: 0.024092..  Val Accuracy: 99.29%\n",
      "Epoch: 310/500..  Training Loss: 0.001453..  Val Loss: 0.025705..  Val Accuracy: 99.32%\n",
      "Epoch: 311/500..  Training Loss: 0.001685..  Val Loss: 0.017897..  Val Accuracy: 99.50%\n",
      "Epoch: 312/500..  Training Loss: 0.001773..  Val Loss: 0.016479..  Val Accuracy: 99.55%\n",
      "Epoch: 313/500..  Training Loss: 0.002203..  Val Loss: 0.015976..  Val Accuracy: 99.52%\n",
      "Epoch: 314/500..  Training Loss: 0.002350..  Val Loss: 0.013395..  Val Accuracy: 99.54%\n",
      "Validation loss decreased (4.437457 --> 4.179195).  Saving model ...\n",
      "Epoch: 315/500..  Training Loss: 0.003077..  Val Loss: 0.017362..  Val Accuracy: 99.46%\n",
      "Epoch: 316/500..  Training Loss: 0.002671..  Val Loss: 0.017283..  Val Accuracy: 99.59%\n",
      "Epoch: 317/500..  Training Loss: 0.003063..  Val Loss: 0.020183..  Val Accuracy: 99.55%\n",
      "Epoch: 319/500..  Training Loss: 0.000204..  Val Loss: 0.019950..  Val Accuracy: 99.34%\n",
      "Epoch: 320/500..  Training Loss: 0.000210..  Val Loss: 0.016817..  Val Accuracy: 99.57%\n",
      "Epoch: 321/500..  Training Loss: 0.000389..  Val Loss: 0.016992..  Val Accuracy: 99.55%\n",
      "Epoch: 322/500..  Training Loss: 0.000629..  Val Loss: 0.019695..  Val Accuracy: 99.44%\n",
      "Epoch: 323/500..  Training Loss: 0.001321..  Val Loss: 0.018201..  Val Accuracy: 99.47%\n",
      "Epoch: 324/500..  Training Loss: 0.000944..  Val Loss: 0.021801..  Val Accuracy: 99.46%\n",
      "Epoch: 325/500..  Training Loss: 0.001631..  Val Loss: 0.017067..  Val Accuracy: 99.52%\n",
      "Epoch: 326/500..  Training Loss: 0.001149..  Val Loss: 0.017798..  Val Accuracy: 99.55%\n",
      "Epoch: 327/500..  Training Loss: 0.003985..  Val Loss: 0.015976..  Val Accuracy: 99.50%\n",
      "Epoch: 328/500..  Training Loss: 0.002095..  Val Loss: 0.019028..  Val Accuracy: 99.49%\n",
      "Epoch: 329/500..  Training Loss: 0.002677..  Val Loss: 0.021253..  Val Accuracy: 99.46%\n",
      "Epoch: 330/500..  Training Loss: 0.001349..  Val Loss: 0.018670..  Val Accuracy: 99.53%\n",
      "Epoch: 331/500..  Training Loss: 0.002352..  Val Loss: 0.023271..  Val Accuracy: 99.39%\n",
      "Epoch: 332/500..  Training Loss: 0.002968..  Val Loss: 0.027167..  Val Accuracy: 99.32%\n",
      "Epoch: 333/500..  Training Loss: 0.003280..  Val Loss: 0.016367..  Val Accuracy: 99.56%\n",
      "Epoch: 335/500..  Training Loss: 0.000195..  Val Loss: 0.021762..  Val Accuracy: 99.44%\n",
      "Epoch: 336/500..  Training Loss: 0.000303..  Val Loss: 0.015383..  Val Accuracy: 99.55%\n",
      "Epoch: 337/500..  Training Loss: 0.000411..  Val Loss: 0.015431..  Val Accuracy: 99.53%\n",
      "Epoch: 338/500..  Training Loss: 0.000540..  Val Loss: 0.013924..  Val Accuracy: 99.54%\n",
      "Epoch: 339/500..  Training Loss: 0.001275..  Val Loss: 0.020395..  Val Accuracy: 99.44%\n",
      "Epoch: 340/500..  Training Loss: 0.000746..  Val Loss: 0.019221..  Val Accuracy: 99.56%\n",
      "Epoch: 341/500..  Training Loss: 0.001203..  Val Loss: 0.020109..  Val Accuracy: 99.48%\n",
      "Epoch: 342/500..  Training Loss: 0.001046..  Val Loss: 0.019663..  Val Accuracy: 99.42%\n",
      "Epoch: 343/500..  Training Loss: 0.001745..  Val Loss: 0.018922..  Val Accuracy: 99.54%\n",
      "Epoch: 344/500..  Training Loss: 0.001695..  Val Loss: 0.026008..  Val Accuracy: 99.43%\n",
      "Epoch: 345/500..  Training Loss: 0.003369..  Val Loss: 0.015992..  Val Accuracy: 99.52%\n",
      "Epoch: 346/500..  Training Loss: 0.002589..  Val Loss: 0.024670..  Val Accuracy: 99.32%\n",
      "Epoch: 347/500..  Training Loss: 0.002442..  Val Loss: 0.015248..  Val Accuracy: 99.52%\n",
      "Epoch: 348/500..  Training Loss: 0.004418..  Val Loss: 0.018511..  Val Accuracy: 99.40%\n",
      "Epoch: 349/500..  Training Loss: 0.002725..  Val Loss: 0.017370..  Val Accuracy: 99.48%\n",
      "Epoch: 351/500..  Training Loss: 0.000124..  Val Loss: 0.020121..  Val Accuracy: 99.46%\n",
      "Epoch: 352/500..  Training Loss: 0.000210..  Val Loss: 0.017912..  Val Accuracy: 99.38%\n",
      "Epoch: 353/500..  Training Loss: 0.000873..  Val Loss: 0.027974..  Val Accuracy: 99.28%\n",
      "Epoch: 354/500..  Training Loss: 0.001051..  Val Loss: 0.018304..  Val Accuracy: 99.49%\n",
      "Epoch: 355/500..  Training Loss: 0.000458..  Val Loss: 0.020894..  Val Accuracy: 99.50%\n",
      "Epoch: 356/500..  Training Loss: 0.000595..  Val Loss: 0.022417..  Val Accuracy: 99.50%\n",
      "Epoch: 357/500..  Training Loss: 0.001378..  Val Loss: 0.037061..  Val Accuracy: 99.12%\n",
      "Epoch: 358/500..  Training Loss: 0.001113..  Val Loss: 0.018896..  Val Accuracy: 99.47%\n",
      "Epoch: 359/500..  Training Loss: 0.002148..  Val Loss: 0.019604..  Val Accuracy: 99.41%\n",
      "Epoch: 360/500..  Training Loss: 0.002108..  Val Loss: 0.017070..  Val Accuracy: 99.44%\n",
      "Epoch: 361/500..  Training Loss: 0.002755..  Val Loss: 0.015970..  Val Accuracy: 99.50%\n",
      "Epoch: 362/500..  Training Loss: 0.003185..  Val Loss: 0.017854..  Val Accuracy: 99.46%\n",
      "Epoch: 363/500..  Training Loss: 0.002168..  Val Loss: 0.016571..  Val Accuracy: 99.56%\n",
      "Epoch: 364/500..  Training Loss: 0.002600..  Val Loss: 0.021040..  Val Accuracy: 99.50%\n",
      "Epoch: 365/500..  Training Loss: 0.002688..  Val Loss: 0.019556..  Val Accuracy: 99.43%\n",
      "Epoch: 367/500..  Training Loss: 0.000381..  Val Loss: 0.032273..  Val Accuracy: 99.28%\n",
      "Epoch: 368/500..  Training Loss: 0.000432..  Val Loss: 0.019232..  Val Accuracy: 99.47%\n",
      "Epoch: 369/500..  Training Loss: 0.000616..  Val Loss: 0.018194..  Val Accuracy: 99.44%\n",
      "Epoch: 370/500..  Training Loss: 0.000505..  Val Loss: 0.019091..  Val Accuracy: 99.45%\n",
      "Epoch: 371/500..  Training Loss: 0.001236..  Val Loss: 0.019906..  Val Accuracy: 99.38%\n",
      "Epoch: 372/500..  Training Loss: 0.001154..  Val Loss: 0.019648..  Val Accuracy: 99.45%\n",
      "Epoch: 373/500..  Training Loss: 0.000934..  Val Loss: 0.016607..  Val Accuracy: 99.53%\n",
      "Epoch: 374/500..  Training Loss: 0.000749..  Val Loss: 0.022929..  Val Accuracy: 99.44%\n",
      "Epoch: 375/500..  Training Loss: 0.001534..  Val Loss: 0.023000..  Val Accuracy: 99.31%\n",
      "Epoch: 376/500..  Training Loss: 0.001846..  Val Loss: 0.021272..  Val Accuracy: 99.49%\n",
      "Epoch: 377/500..  Training Loss: 0.002854..  Val Loss: 0.024180..  Val Accuracy: 99.34%\n",
      "Epoch: 378/500..  Training Loss: 0.002826..  Val Loss: 0.017144..  Val Accuracy: 99.52%\n",
      "Epoch: 379/500..  Training Loss: 0.002261..  Val Loss: 0.020766..  Val Accuracy: 99.43%\n",
      "Epoch: 380/500..  Training Loss: 0.003314..  Val Loss: 0.019414..  Val Accuracy: 99.47%\n",
      "Epoch: 382/500..  Training Loss: 0.000000..  Val Loss: 0.021792..  Val Accuracy: 99.46%\n",
      "Epoch: 383/500..  Training Loss: 0.000191..  Val Loss: 0.020235..  Val Accuracy: 99.35%\n",
      "Epoch: 384/500..  Training Loss: 0.000266..  Val Loss: 0.016728..  Val Accuracy: 99.54%\n",
      "Epoch: 385/500..  Training Loss: 0.000791..  Val Loss: 0.019249..  Val Accuracy: 99.48%\n",
      "Epoch: 386/500..  Training Loss: 0.000563..  Val Loss: 0.035814..  Val Accuracy: 99.18%\n",
      "Epoch: 387/500..  Training Loss: 0.000986..  Val Loss: 0.026316..  Val Accuracy: 99.34%\n",
      "Epoch: 388/500..  Training Loss: 0.001378..  Val Loss: 0.024739..  Val Accuracy: 99.35%\n",
      "Epoch: 389/500..  Training Loss: 0.001448..  Val Loss: 0.017001..  Val Accuracy: 99.54%\n",
      "Epoch: 390/500..  Training Loss: 0.001256..  Val Loss: 0.020592..  Val Accuracy: 99.46%\n",
      "Epoch: 391/500..  Training Loss: 0.001102..  Val Loss: 0.020036..  Val Accuracy: 99.48%\n",
      "Epoch: 392/500..  Training Loss: 0.002445..  Val Loss: 0.027079..  Val Accuracy: 99.29%\n",
      "Epoch: 393/500..  Training Loss: 0.001831..  Val Loss: 0.015299..  Val Accuracy: 99.58%\n",
      "Epoch: 394/500..  Training Loss: 0.002494..  Val Loss: 0.019114..  Val Accuracy: 99.48%\n",
      "Epoch: 395/500..  Training Loss: 0.002340..  Val Loss: 0.018612..  Val Accuracy: 99.53%\n",
      "Epoch: 396/500..  Training Loss: 0.002224..  Val Loss: 0.021296..  Val Accuracy: 99.41%\n",
      "Epoch: 398/500..  Training Loss: 0.000001..  Val Loss: 0.016022..  Val Accuracy: 99.49%\n",
      "Epoch: 399/500..  Training Loss: 0.000186..  Val Loss: 0.019673..  Val Accuracy: 99.44%\n",
      "Epoch: 400/500..  Training Loss: 0.000308..  Val Loss: 0.019348..  Val Accuracy: 99.55%\n",
      "Epoch: 401/500..  Training Loss: 0.000597..  Val Loss: 0.023735..  Val Accuracy: 99.46%\n",
      "Epoch: 402/500..  Training Loss: 0.000815..  Val Loss: 0.019982..  Val Accuracy: 99.48%\n",
      "Epoch: 403/500..  Training Loss: 0.001376..  Val Loss: 0.017906..  Val Accuracy: 99.54%\n",
      "Epoch: 404/500..  Training Loss: 0.001156..  Val Loss: 0.018007..  Val Accuracy: 99.49%\n",
      "Epoch: 405/500..  Training Loss: 0.000994..  Val Loss: 0.019710..  Val Accuracy: 99.46%\n",
      "Epoch: 406/500..  Training Loss: 0.001624..  Val Loss: 0.019994..  Val Accuracy: 99.38%\n",
      "Epoch: 407/500..  Training Loss: 0.001126..  Val Loss: 0.021333..  Val Accuracy: 99.45%\n",
      "Epoch: 408/500..  Training Loss: 0.001851..  Val Loss: 0.016464..  Val Accuracy: 99.53%\n",
      "Epoch: 409/500..  Training Loss: 0.002183..  Val Loss: 0.021003..  Val Accuracy: 99.44%\n",
      "Epoch: 410/500..  Training Loss: 0.001611..  Val Loss: 0.017400..  Val Accuracy: 99.58%\n",
      "Epoch: 411/500..  Training Loss: 0.004330..  Val Loss: 0.019307..  Val Accuracy: 99.40%\n",
      "Epoch: 412/500..  Training Loss: 0.002247..  Val Loss: 0.016250..  Val Accuracy: 99.55%\n",
      "Epoch: 414/500..  Training Loss: 0.000022..  Val Loss: 0.021944..  Val Accuracy: 99.41%\n",
      "Epoch: 415/500..  Training Loss: 0.000225..  Val Loss: 0.020285..  Val Accuracy: 99.44%\n",
      "Epoch: 416/500..  Training Loss: 0.000616..  Val Loss: 0.017379..  Val Accuracy: 99.47%\n",
      "Epoch: 417/500..  Training Loss: 0.000246..  Val Loss: 0.017309..  Val Accuracy: 99.54%\n",
      "Epoch: 418/500..  Training Loss: 0.000253..  Val Loss: 0.021628..  Val Accuracy: 99.38%\n",
      "Epoch: 419/500..  Training Loss: 0.000643..  Val Loss: 0.020598..  Val Accuracy: 99.57%\n",
      "Epoch: 420/500..  Training Loss: 0.001786..  Val Loss: 0.019149..  Val Accuracy: 99.48%\n",
      "Epoch: 421/500..  Training Loss: 0.001636..  Val Loss: 0.018837..  Val Accuracy: 99.44%\n",
      "Epoch: 422/500..  Training Loss: 0.001101..  Val Loss: 0.019337..  Val Accuracy: 99.48%\n",
      "Epoch: 423/500..  Training Loss: 0.001250..  Val Loss: 0.023141..  Val Accuracy: 99.43%\n",
      "Epoch: 424/500..  Training Loss: 0.001781..  Val Loss: 0.026633..  Val Accuracy: 99.36%\n",
      "Epoch: 425/500..  Training Loss: 0.001686..  Val Loss: 0.016682..  Val Accuracy: 99.46%\n",
      "Epoch: 426/500..  Training Loss: 0.001580..  Val Loss: 0.018630..  Val Accuracy: 99.45%\n",
      "Epoch: 427/500..  Training Loss: 0.002072..  Val Loss: 0.015701..  Val Accuracy: 99.57%\n",
      "Epoch: 428/500..  Training Loss: 0.003730..  Val Loss: 0.017518..  Val Accuracy: 99.43%\n",
      "Epoch: 430/500..  Training Loss: 0.000084..  Val Loss: 0.016861..  Val Accuracy: 99.49%\n",
      "Epoch: 431/500..  Training Loss: 0.000283..  Val Loss: 0.016479..  Val Accuracy: 99.48%\n",
      "Epoch: 432/500..  Training Loss: 0.001030..  Val Loss: 0.019298..  Val Accuracy: 99.35%\n",
      "Epoch: 433/500..  Training Loss: 0.000310..  Val Loss: 0.019739..  Val Accuracy: 99.45%\n",
      "Epoch: 434/500..  Training Loss: 0.000580..  Val Loss: 0.014782..  Val Accuracy: 99.54%\n",
      "Epoch: 435/500..  Training Loss: 0.001076..  Val Loss: 0.017374..  Val Accuracy: 99.57%\n",
      "Epoch: 436/500..  Training Loss: 0.001035..  Val Loss: 0.023526..  Val Accuracy: 99.38%\n",
      "Epoch: 437/500..  Training Loss: 0.001301..  Val Loss: 0.022271..  Val Accuracy: 99.37%\n",
      "Epoch: 438/500..  Training Loss: 0.001633..  Val Loss: 0.018608..  Val Accuracy: 99.48%\n",
      "Epoch: 439/500..  Training Loss: 0.000909..  Val Loss: 0.018095..  Val Accuracy: 99.49%\n",
      "Epoch: 440/500..  Training Loss: 0.002359..  Val Loss: 0.019323..  Val Accuracy: 99.50%\n",
      "Epoch: 441/500..  Training Loss: 0.001574..  Val Loss: 0.025751..  Val Accuracy: 99.38%\n",
      "Epoch: 442/500..  Training Loss: 0.002509..  Val Loss: 0.020500..  Val Accuracy: 99.46%\n",
      "Epoch: 443/500..  Training Loss: 0.003903..  Val Loss: 0.022792..  Val Accuracy: 99.39%\n",
      "Epoch: 444/500..  Training Loss: 0.002144..  Val Loss: 0.020783..  Val Accuracy: 99.52%\n",
      "Epoch: 446/500..  Training Loss: 0.000074..  Val Loss: 0.021907..  Val Accuracy: 99.50%\n",
      "Epoch: 447/500..  Training Loss: 0.000293..  Val Loss: 0.020451..  Val Accuracy: 99.48%\n",
      "Epoch: 448/500..  Training Loss: 0.000206..  Val Loss: 0.021048..  Val Accuracy: 99.44%\n",
      "Epoch: 449/500..  Training Loss: 0.000779..  Val Loss: 0.015975..  Val Accuracy: 99.52%\n",
      "Epoch: 450/500..  Training Loss: 0.000543..  Val Loss: 0.018400..  Val Accuracy: 99.58%\n",
      "Epoch: 451/500..  Training Loss: 0.000622..  Val Loss: 0.020935..  Val Accuracy: 99.46%\n",
      "Epoch: 452/500..  Training Loss: 0.001748..  Val Loss: 0.024535..  Val Accuracy: 99.33%\n",
      "Epoch: 453/500..  Training Loss: 0.001837..  Val Loss: 0.020888..  Val Accuracy: 99.43%\n",
      "Epoch: 454/500..  Training Loss: 0.000851..  Val Loss: 0.017756..  Val Accuracy: 99.51%\n",
      "Epoch: 455/500..  Training Loss: 0.001384..  Val Loss: 0.020228..  Val Accuracy: 99.46%\n",
      "Epoch: 456/500..  Training Loss: 0.001027..  Val Loss: 0.018645..  Val Accuracy: 99.44%\n",
      "Epoch: 457/500..  Training Loss: 0.002831..  Val Loss: 0.022351..  Val Accuracy: 99.40%\n",
      "Epoch: 458/500..  Training Loss: 0.001828..  Val Loss: 0.024167..  Val Accuracy: 99.36%\n",
      "Epoch: 459/500..  Training Loss: 0.001496..  Val Loss: 0.016074..  Val Accuracy: 99.55%\n",
      "Epoch: 460/500..  Training Loss: 0.002425..  Val Loss: 0.020554..  Val Accuracy: 99.45%\n",
      "Epoch: 462/500..  Training Loss: 0.000114..  Val Loss: 0.028075..  Val Accuracy: 99.36%\n",
      "Epoch: 463/500..  Training Loss: 0.000562..  Val Loss: 0.019749..  Val Accuracy: 99.41%\n",
      "Epoch: 464/500..  Training Loss: 0.000288..  Val Loss: 0.021730..  Val Accuracy: 99.41%\n",
      "Epoch: 465/500..  Training Loss: 0.000898..  Val Loss: 0.025417..  Val Accuracy: 99.31%\n",
      "Epoch: 466/500..  Training Loss: 0.000847..  Val Loss: 0.018785..  Val Accuracy: 99.43%\n",
      "Epoch: 467/500..  Training Loss: 0.000939..  Val Loss: 0.017534..  Val Accuracy: 99.56%\n",
      "Epoch: 468/500..  Training Loss: 0.001455..  Val Loss: 0.017617..  Val Accuracy: 99.43%\n",
      "Epoch: 469/500..  Training Loss: 0.001041..  Val Loss: 0.020082..  Val Accuracy: 99.46%\n",
      "Epoch: 470/500..  Training Loss: 0.001129..  Val Loss: 0.022158..  Val Accuracy: 99.47%\n",
      "Epoch: 471/500..  Training Loss: 0.001541..  Val Loss: 0.020365..  Val Accuracy: 99.53%\n",
      "Epoch: 472/500..  Training Loss: 0.002140..  Val Loss: 0.018361..  Val Accuracy: 99.49%\n",
      "Epoch: 473/500..  Training Loss: 0.001705..  Val Loss: 0.023771..  Val Accuracy: 99.44%\n",
      "Epoch: 474/500..  Training Loss: 0.001901..  Val Loss: 0.014715..  Val Accuracy: 99.58%\n",
      "Epoch: 475/500..  Training Loss: 0.002264..  Val Loss: 0.016142..  Val Accuracy: 99.53%\n",
      "Epoch: 476/500..  Training Loss: 0.001870..  Val Loss: 0.017276..  Val Accuracy: 99.51%\n",
      "Epoch: 478/500..  Training Loss: 0.000084..  Val Loss: 0.019031..  Val Accuracy: 99.47%\n",
      "Epoch: 479/500..  Training Loss: 0.000282..  Val Loss: 0.022060..  Val Accuracy: 99.47%\n",
      "Epoch: 480/500..  Training Loss: 0.000413..  Val Loss: 0.019061..  Val Accuracy: 99.51%\n",
      "Epoch: 481/500..  Training Loss: 0.001513..  Val Loss: 0.018491..  Val Accuracy: 99.44%\n",
      "Epoch: 482/500..  Training Loss: 0.000760..  Val Loss: 0.018724..  Val Accuracy: 99.45%\n",
      "Epoch: 483/500..  Training Loss: 0.000946..  Val Loss: 0.022092..  Val Accuracy: 99.44%\n",
      "Epoch: 484/500..  Training Loss: 0.000908..  Val Loss: 0.015518..  Val Accuracy: 99.56%\n",
      "Epoch: 485/500..  Training Loss: 0.000739..  Val Loss: 0.020968..  Val Accuracy: 99.37%\n",
      "Epoch: 486/500..  Training Loss: 0.000829..  Val Loss: 0.023442..  Val Accuracy: 99.35%\n",
      "Epoch: 487/500..  Training Loss: 0.001354..  Val Loss: 0.016849..  Val Accuracy: 99.43%\n",
      "Epoch: 488/500..  Training Loss: 0.001839..  Val Loss: 0.021709..  Val Accuracy: 99.40%\n",
      "Epoch: 489/500..  Training Loss: 0.002534..  Val Loss: 0.016775..  Val Accuracy: 99.49%\n",
      "Epoch: 490/500..  Training Loss: 0.001627..  Val Loss: 0.020938..  Val Accuracy: 99.43%\n",
      "Epoch: 491/500..  Training Loss: 0.001669..  Val Loss: 0.019065..  Val Accuracy: 99.43%\n",
      "Epoch: 492/500..  Training Loss: 0.002032..  Val Loss: 0.019450..  Val Accuracy: 99.44%\n",
      "Epoch: 494/500..  Training Loss: 0.000065..  Val Loss: 0.020121..  Val Accuracy: 99.47%\n",
      "Epoch: 495/500..  Training Loss: 0.000068..  Val Loss: 0.020374..  Val Accuracy: 99.46%\n",
      "Epoch: 496/500..  Training Loss: 0.000892..  Val Loss: 0.020337..  Val Accuracy: 99.41%\n",
      "Epoch: 497/500..  Training Loss: 0.000516..  Val Loss: 0.022018..  Val Accuracy: 99.43%\n",
      "Epoch: 498/500..  Training Loss: 0.000990..  Val Loss: 0.019461..  Val Accuracy: 99.43%\n",
      "Epoch: 499/500..  Training Loss: 0.000614..  Val Loss: 0.017727..  Val Accuracy: 99.49%\n",
      "Epoch: 500/500..  Training Loss: 0.000659..  Val Loss: 0.018166..  Val Accuracy: 99.39%\n"
     ]
    }
   ],
   "source": [
    "ensemble1_best=final(ensemble1,cross_val_train_set,cross_val_train_label,cross_val_test_set,cross_val_test_label,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b51b6-5be8-4a71-9660-6632a3995b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c84b3-5573-4515-9faa-fcdde9a775e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b985c1a-938d-41c8-8b4f-d7e5203ef3d4",
   "metadata": {},
   "source": [
    "### 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c5ad0-c4ec-4455-b87d-cce03b9e834c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ded44a-63e9-4450-b348-fecd3ca0ad30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(classifier1,classifier2,classifier3,classifier4,classifier5, dataloader):\n",
    "    # setup the network\n",
    "    predlist=[]\n",
    "    real=[]    \n",
    "\n",
    "    classifier.eval()\n",
    "    correct = 0.0\n",
    "    \n",
    "    max_tr_score = 0\n",
    "    max_val_score = 0\n",
    "    for batch_idx, (data) in enumerate(dataloader):\n",
    "    \n",
    "        signal1,label = data\n",
    "        signal1,label = Variable(signal1.cuda()),Variable(label.cuda().long())\n",
    "        \n",
    "        \n",
    "        out1,_ = classifier1(signal1)\n",
    "        out2,_ = classifier2(signal1) \n",
    "        out3,_ = classifier3(signal1)\n",
    "        out4,_ = classifier4(signal1)\n",
    "        out5,_ = classifier5(signal1)\n",
    "\n",
    "        \n",
    "        out=(out1+out2+out3+out4+out5)/5\n",
    "        \n",
    "        pred = out.data.max(1, keepdim= True)[1]\n",
    "        predlist.append(pred.cpu().detach().numpy().squeeze())\n",
    "        real.append(label)        \n",
    "        correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        # predlist.append(pred)\n",
    "    print('\\nAccuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        correct, len(dataloader.dataset), 100. * float(correct) / len(dataloader.dataset)))\n",
    "    acc=100. * float(correct) / len(dataloader.dataset)\n",
    "    return acc,predlist,real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8ec66-a23a-4bd2-9abc-b49849ca3ad4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd648ff7-a427-4099-9386-0c860d99804b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader,valid_loader,test_loader=loaders(cross_val_train_set_1,cross_val_train_label_1,cross_val_test_set_1,cross_val_test_label_1,1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f8ec43-e3aa-4e78-a821-fea9faccd386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc,predlist,realist=test(ensemble1_best,ensemble2_best,ensemble3_best,ensemble4_best,ensemble5_best,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc739f-7bce-425a-8fee-3ebef427d754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusionmatrix(predlist, realist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698490b-77dc-4aaf-b977-4c5700a016b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331433cb-4623-4dad-b6dd-e6fc3290c88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c228b-f4d2-4b53-80ea-101110f539d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654cc06c-b94b-47ba-865e-bc762fa7a391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb846d9-63ed-4b2b-b323-03cee63ba82c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b8c57a3-20e1-47ca-973f-b1296db7f078",
   "metadata": {},
   "source": [
    "### Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4525ed6c-7e68-4b46-abb9-11a418c1eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fail_index(pred, real, cross_val_num):\n",
    "    failed=[]\n",
    "    with open('test_fold_index.pickle', 'rb') as f:\n",
    "        test_fold_index = pickle.load(f)\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        if pred[i].item()!=real[i].detach().cpu().item():\n",
    "            failed.append(test_fold_index[cross_val_num-1][i])\n",
    "    \n",
    "    return failed\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce5ca299-b530-48d5-b341-37c9e4ed0b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_index=fail_index(predlist,realist,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9eced31-f171-4ad6-99a6-5ad3b58c0844",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65,\n",
       " 186,\n",
       " 412,\n",
       " 440,\n",
       " 508,\n",
       " 516,\n",
       " 573,\n",
       " 579,\n",
       " 583,\n",
       " 655,\n",
       " 656,\n",
       " 795,\n",
       " 908,\n",
       " 951,\n",
       " 994,\n",
       " 1003,\n",
       " 1054,\n",
       " 1060,\n",
       " 1168,\n",
       " 1241,\n",
       " 1261,\n",
       " 1269,\n",
       " 1314,\n",
       " 1550,\n",
       " 1608,\n",
       " 1774,\n",
       " 1874,\n",
       " 1883,\n",
       " 1891,\n",
       " 2021,\n",
       " 2128,\n",
       " 2183,\n",
       " 2305,\n",
       " 2376,\n",
       " 2429,\n",
       " 2463,\n",
       " 2472,\n",
       " 2555,\n",
       " 2638,\n",
       " 2736,\n",
       " 2870,\n",
       " 2927,\n",
       " 2938,\n",
       " 3151,\n",
       " 3395,\n",
       " 3559,\n",
       " 3565,\n",
       " 3754,\n",
       " 3846,\n",
       " 3902,\n",
       " 3992,\n",
       " 4148,\n",
       " 4249,\n",
       " 4263,\n",
       " 4485,\n",
       " 4498,\n",
       " 4536,\n",
       " 4599,\n",
       " 4625,\n",
       " 4731,\n",
       " 5028,\n",
       " 5080,\n",
       " 5099,\n",
       " 5185,\n",
       " 5265,\n",
       " 5333,\n",
       " 5369,\n",
       " 5534,\n",
       " 5596,\n",
       " 5641,\n",
       " 5680,\n",
       " 6041,\n",
       " 6171,\n",
       " 6174,\n",
       " 6343,\n",
       " 6480,\n",
       " 6526,\n",
       " 6621,\n",
       " 6722,\n",
       " 6759,\n",
       " 6760,\n",
       " 7044,\n",
       " 7083,\n",
       " 7256,\n",
       " 7303,\n",
       " 7372,\n",
       " 7435,\n",
       " 7447,\n",
       " 7509,\n",
       " 7587,\n",
       " 7816,\n",
       " 7901,\n",
       " 8016,\n",
       " 8034,\n",
       " 8229,\n",
       " 8282,\n",
       " 8506,\n",
       " 8531,\n",
       " 8574,\n",
       " 8666,\n",
       " 8669,\n",
       " 8673,\n",
       " 8680,\n",
       " 8710,\n",
       " 8745,\n",
       " 8768,\n",
       " 8803,\n",
       " 8806,\n",
       " 8938,\n",
       " 9126,\n",
       " 9163,\n",
       " 9265,\n",
       " 9384,\n",
       " 9387,\n",
       " 9414,\n",
       " 9424,\n",
       " 9482,\n",
       " 9525,\n",
       " 9778,\n",
       " 9920,\n",
       " 10064,\n",
       " 10092,\n",
       " 10144,\n",
       " 10189,\n",
       " 10211,\n",
       " 10471,\n",
       " 10500,\n",
       " 10519,\n",
       " 10535,\n",
       " 10633,\n",
       " 10808,\n",
       " 10866,\n",
       " 10869,\n",
       " 10879,\n",
       " 10882,\n",
       " 11017,\n",
       " 11143,\n",
       " 11204,\n",
       " 11256,\n",
       " 11286,\n",
       " 11361,\n",
       " 11365,\n",
       " 11376,\n",
       " 11454,\n",
       " 11498,\n",
       " 11537,\n",
       " 11679,\n",
       " 11797,\n",
       " 11934,\n",
       " 12040,\n",
       " 12131,\n",
       " 12350,\n",
       " 12395,\n",
       " 12444,\n",
       " 12456,\n",
       " 12752,\n",
       " 12843,\n",
       " 12929,\n",
       " 12946,\n",
       " 13030,\n",
       " 13230,\n",
       " 13244,\n",
       " 13265,\n",
       " 13346,\n",
       " 13462,\n",
       " 13609,\n",
       " 13833,\n",
       " 13838,\n",
       " 13904,\n",
       " 14187,\n",
       " 14198,\n",
       " 14512,\n",
       " 14542,\n",
       " 14701,\n",
       " 14764,\n",
       " 14772,\n",
       " 14773,\n",
       " 14893,\n",
       " 14902,\n",
       " 14951,\n",
       " 15118,\n",
       " 15171,\n",
       " 15259,\n",
       " 15305,\n",
       " 15338,\n",
       " 15348,\n",
       " 15824,\n",
       " 16123,\n",
       " 16135,\n",
       " 16186,\n",
       " 16255,\n",
       " 16339,\n",
       " 16390,\n",
       " 16417,\n",
       " 16423,\n",
       " 16437,\n",
       " 16606,\n",
       " 16712,\n",
       " 16783,\n",
       " 16810,\n",
       " 16835,\n",
       " 16836,\n",
       " 17043,\n",
       " 17262,\n",
       " 17269,\n",
       " 17352,\n",
       " 17403,\n",
       " 17438,\n",
       " 17449,\n",
       " 17471,\n",
       " 17484,\n",
       " 17615,\n",
       " 17641,\n",
       " 17797,\n",
       " 17887,\n",
       " 17901,\n",
       " 17949,\n",
       " 18053,\n",
       " 18105,\n",
       " 18223,\n",
       " 18229,\n",
       " 18343,\n",
       " 18420,\n",
       " 18484,\n",
       " 18488,\n",
       " 18621,\n",
       " 18703,\n",
       " 18740,\n",
       " 18860,\n",
       " 18861,\n",
       " 19022,\n",
       " 19117,\n",
       " 19249,\n",
       " 19320,\n",
       " 19382,\n",
       " 19410,\n",
       " 19467,\n",
       " 19489,\n",
       " 19610,\n",
       " 19727,\n",
       " 19742,\n",
       " 19788,\n",
       " 19895,\n",
       " 19910,\n",
       " 20093,\n",
       " 20106]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
