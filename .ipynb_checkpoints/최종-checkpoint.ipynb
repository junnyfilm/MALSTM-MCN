{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e69afd-a28e-4614-a0cb-b8175f53a740",
   "metadata": {},
   "source": [
    "## 앙상블 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a883b28-8116-4e84-8e76-67abeb292951",
   "metadata": {},
   "source": [
    "- cv값이랑 cond값 지정해주세요 cv 5, cond 2 , 내부 앙상블 5개 => 총 50개 모델 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3cd2321-b65d-47a4-9efa-23314bdb0962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv=3\n",
    "cond=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f799a1-ddfc-4159-8de8-165d7f76bf0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from numpy import inf\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import pickle\n",
    "import argparse, sys, os\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "import torchvision.transforms.functional as Fv\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchsummary import summary\n",
    "from torch.optim import lr_scheduler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch import topk\n",
    "from tqdm.notebook import tqdm # 프로세스 바\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "# device = torch.device(\"cuda:%d\" % 0 if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "# from dataloader_hilbert_att import DataLoader\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b8c41b-2954-4211-a543-dad65a5369f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path= \"\\\\\\\\147.47.239.143\\\\SHRM-robotgear\\\\ICPHM2023\\\\pickle\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "484b5952-58a5-4748-b062-93175e206d37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # read data\n",
    "\n",
    "with open(path+'cross_val_train_set_'+str(cv)+'_'+str(cond)+'.pickle', 'rb') as f:\n",
    "    cross_val_train_set = pickle.load(f)\n",
    "with open(path+'cross_val_train_label_'+str(cv)+'_'+str(cond)+'.pickle', 'rb') as f:\n",
    "    cross_val_train_label = pickle.load(f)\n",
    "with open(path+'cross_val_test_set_'+str(cv)+'_'+str(cond)+'.pickle', 'rb') as f:\n",
    "    cross_val_test_set = pickle.load(f)\n",
    "with open(path+'cross_val_test_label_'+str(cv)+'_'+str(cond)+'.pickle', 'rb') as f:\n",
    "    cross_val_test_label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cad946e-c35f-4762-9647-dc6488cc4352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#depthwise version\n",
    "class customdataset(Dataset):\n",
    "    def __init__(self, data, label): \n",
    "        super().__init__()\n",
    "        self.data=torch.tensor(data)\n",
    "        self.label=torch.tensor(label)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        label = self.label[idx] \n",
    "                \n",
    "        return  x.to(device).float(), label.to(device).long()\n",
    "\n",
    "def loaders(tr_data,tr_label,ts_data,ts_label,random_state):\n",
    "    train_set, valid_set, train_label, valid_label = train_test_split(tr_data, tr_label,random_state=random_state, train_size=0.75)\n",
    "    \n",
    "    traindataset = customdataset(train_set, train_label)\n",
    "    validdataset = customdataset(valid_set, valid_label)\n",
    "    testdataset = customdataset(ts_data, ts_label)\n",
    "    \n",
    "    traindataloader = DataLoader(traindataset, batch_size=32, shuffle=True, drop_last=True )\n",
    "    validdataloader = DataLoader(validdataset, batch_size=32, shuffle=True, drop_last=True )\n",
    "    testdataloader = DataLoader(testdataset, batch_size=1, shuffle=False, drop_last=False )\n",
    "    \n",
    "    return traindataloader,validdataloader,testdataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8771177-fe83-4f73-b2d1-b12590ff3b1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f19a6ca-b731-4775-af5f-708bcc055787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "savepath= '\\\\\\\\147.47.239.143\\\\SHRM-robotgear\\\\ICPHM2023\\\\형민\\\\2023 ICPHM\\\\앙상블모델\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a6adc-be63-49c7-b19f-a33b77237cde",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 기본 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f78f6216-a72c-44a4-a138-fd819810c83f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7efd1e-386a-484f-aefa-31da02d7bbdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dilated_Module(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Dilated_Module,self).__init__()\n",
    "        self.conv1=nn.Conv1d(in_channels, int(out_channels/4), kernel_size = 5, stride = 1, padding = ((5)//2), dilation=1, bias=False)        \n",
    "        self.conv2=nn.Conv1d(in_channels, int(out_channels/4), kernel_size = 5, stride = 1, padding = ((5+4*2)//2), dilation=3, bias=False)        \n",
    "        self.conv3=nn.Conv1d(in_channels, int(out_channels/4), kernel_size = 5, stride = 1, padding = ((5+4*4)//2), dilation=5, bias=False)\n",
    "        self.conv4=nn.Conv1d(in_channels, int(out_channels/4), kernel_size = 5, stride = 1, padding = ((5+4*6)//2), dilation=7, bias=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        ''' input x should be in size [B,F,T], where \n",
    "            B = Batch size\n",
    "            F = features\n",
    "            T = Time samples\n",
    "        '''\n",
    "        x1=self.conv1(x)\n",
    "        x2=self.conv2(x)\n",
    "        x3=self.conv3(x)\n",
    "        x4=self.conv4(x)\n",
    "        \n",
    "        y=torch.cat([x1,x2,x3,x4],dim=1)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ecb90b4-6f6b-4f70-b312-cce7166881d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLSTMfcn_MSN(nn.Module):\n",
    "    def __init__(self, *, num_classes, num_features,\n",
    "                 num_lstm_out, num_lstm_layers=1, \n",
    "                 conv1_nf=128, conv2_nf=256, conv3_nf=128,\n",
    "                 lstm_drop_p=0.8, fc_drop_p=0.3):\n",
    "        super(MLSTMfcn_MSN, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = num_features\n",
    "\n",
    "        self.num_lstm_out = num_lstm_out\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "\n",
    "        \n",
    "        self.conv1_nf = conv1_nf\n",
    "        self.conv2_nf = conv2_nf\n",
    "        self.conv3_nf = conv3_nf\n",
    "\n",
    "        self.dilated_1=Dilated_Module(self.num_features, self.conv1_nf)\n",
    "        self.dilated_2=Dilated_Module(self.conv1_nf, self.conv2_nf)\n",
    "        self.dilated_3=Dilated_Module(self.conv2_nf, self.conv3_nf)\n",
    "\n",
    "        self.lstm_drop_p = lstm_drop_p\n",
    "        self.fc_drop_p = fc_drop_p\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.num_features, \n",
    "                            hidden_size=self.num_lstm_out,\n",
    "                            num_layers=self.num_lstm_layers,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(self.conv1_nf)\n",
    "        self.bn2 = nn.BatchNorm1d(self.conv2_nf)\n",
    "        self.bn3 = nn.BatchNorm1d(self.conv3_nf)\n",
    "\n",
    "        self.se1 = SELayer(self.conv1_nf)  # ex 128\n",
    "        self.se2 = SELayer(self.conv2_nf)  # ex 256\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstmDrop = nn.Dropout(self.lstm_drop_p)\n",
    "        self.convDrop = nn.Dropout(self.fc_drop_p)\n",
    "\n",
    "        self.fc = nn.Linear(self.conv3_nf+self.num_lstm_out, self.num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ''' input x should be in size [B,T,F], where \n",
    "            B = Batch size\n",
    "            T = Time samples\n",
    "            F = features\n",
    "        '''\n",
    "        x=x.transpose(2,1)\n",
    "        ''' input x should be in size [B,T,F], where \n",
    "            B = Batch size\n",
    "            T = Time samples\n",
    "            F = features\n",
    "        '''       \n",
    "        # x1 = nn.utils.rnn.pack_padded_sequence(x, seq_lens, \n",
    "        #                                        batch_first=True, \n",
    "        #                                        enforce_sorted=False)\n",
    "        x1, (ht,ct) = self.lstm(x)\n",
    "        x1 = self.lstmDrop(x1)\n",
    "        # x1, _ = nn.utils.rnn.pad_packed_sequence(x1, batch_first=True, \n",
    "        #                                          padding_value=0.0)\n",
    "        # print(x1.size())\n",
    "        x1 = x1[:,-1,:]\n",
    "        \n",
    "        x2 = x.transpose(2,1)\n",
    "        x2 = self.convDrop(self.relu(self.bn1(self.dilated_1(x2))))\n",
    "        # print(x2.size())\n",
    "        x2 = self.se1(x2)\n",
    "        x2 = self.convDrop(self.relu(self.bn2(self.dilated_2(x2))))\n",
    "        # print(x2.size())\n",
    "        x2 = self.se2(x2)\n",
    "        x2 = self.convDrop(self.relu(self.bn3(self.dilated_3(x2))))\n",
    "        # print(x2.size())\n",
    "        x2 = torch.mean(x2,2)\n",
    "        \n",
    "        x_all = torch.cat((x1,x2),dim=1)\n",
    "        x_out = self.fc(x_all)\n",
    "        x_out = F.log_softmax(x_out, dim=1)\n",
    "\n",
    "        return x_out,x_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388992d9-1d9c-40b5-9dd3-4effe3eb9e8a",
   "metadata": {},
   "source": [
    "### 공통실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f084af-b60b-456d-ac62-003e1a66ae4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation(model, testloader, criterion):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for inputs, labels in testloader:\n",
    "        inputs = inputs.float()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        output,_ = model.forward(inputs)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ## Calculating the accuracy \n",
    "        # Model's output is log-softmax, take exponential to get the probabilities\n",
    "        ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8cb164-562c-4ce9-9445-4d6b6c1fcf9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fail_index(pred, real, cross_val_num):\n",
    "    failed=[]\n",
    "    with open('test_fold_index_2.pickle', 'rb') as f:\n",
    "        test_fold_index = pickle.load(f)\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        if pred[i].item()!=real[i].detach().cpu().item():\n",
    "            failed.append(test_fold_index[cross_val_num-1][i])\n",
    "    \n",
    "    return failed\n",
    "\n",
    "import seaborn as sn\n",
    "def confusionmatrix(y_pred1, y_test1, column=['class0','class1','class2','class3','class4']):\n",
    "    # y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    # _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    a=[]\n",
    "    b=[]\n",
    "    for i in range(len(y_test1)):\n",
    "        a.append(y_test1[i].detach().cpu().item())\n",
    "        b.append(y_pred1[i].item())\n",
    "    y_test=a\n",
    "    y_pred=b\n",
    "    df_cm = pd.DataFrame(confusion_matrix(y_test,y_pred))\n",
    "    df_cm.index=column\n",
    "    df_cm.columns=column\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    b, t = plt.ylim() \n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t)\n",
    "    \n",
    "\n",
    "    df_cm =df_cm / df_cm.astype(np.float).sum(axis=1)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    b, t = plt.ylim() \n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t)\n",
    "\n",
    "    \n",
    "def test(classifier, dataloader):\n",
    "    # setup the network\n",
    "    predlist=[]\n",
    "    real=[]    \n",
    "\n",
    "    classifier.eval()\n",
    "    correct = 0.0\n",
    "    \n",
    "    max_tr_score = 0\n",
    "    max_val_score = 0\n",
    "    for batch_idx, (data) in enumerate(dataloader):\n",
    "    \n",
    "        signal1,label = data\n",
    "        signal1,label = Variable(signal1.cuda()),Variable(label.cuda().long())\n",
    "        out,_ = classifier(signal1)   \n",
    "\n",
    "        pred = out.data.max(1, keepdim= True)[1]\n",
    "        predlist.append(pred.cpu().detach().numpy().squeeze())\n",
    "        real.append(label)        \n",
    "        correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        # predlist.append(pred)\n",
    "    print('\\nAccuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        correct, len(dataloader.dataset), 100. * float(correct) / len(dataloader.dataset)))\n",
    "    acc=100. * float(correct) / len(dataloader.dataset)\n",
    "    return acc,predlist,real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66d4b582-2db2-42ca-af1e-5eafb3da0669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "# 하이퍼파라미터 그리드 설정\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.0005, 0.0001],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'hidden_size': [8, 64, 128],\n",
    "    'optimizer': ['Adam', 'RMSprop', 'SGD']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de024bea-2b4f-415c-8887-08f348e64af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = param_grid['lr'][0]\n",
    "batch_size = param_grid['batch_size'][0]\n",
    "num_lstm_out = param_grid['hidden_size'][0]\n",
    "optimizer_name = param_grid['optimizer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7042c4e0-dae0-4533-9e79-ada313ecc451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "randomseedlist=[4444,2514,4040,8282,1004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf442f90-6850-4cee-97f8-642bdf90e5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def final(modelname,train_set, train_label, test_set, test_label,esbnum):\n",
    "    train_loader,valid_loader,test_loader=loaders(train_set, train_label,test_set,test_label,randomseedlist[esbnum])\n",
    "\n",
    "\n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "    criterion = nn.NLLLoss().to(device)\n",
    "    epochs=500\n",
    "    print_every=1000\n",
    "\n",
    "    # 0.001 32 8 Adam\n",
    "    lr = param_grid['lr'][0]\n",
    "    batch_size = param_grid['batch_size'][0]\n",
    "    num_lstm_out = param_grid['hidden_size'][0]\n",
    "    optimizer_name = param_grid['optimizer'][0]\n",
    "\n",
    "    model =modelname.to(device)\n",
    "\n",
    "\n",
    "    # 옵티마이저 설정\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "    #train\n",
    "    steps = 0\n",
    "\n",
    "    for e in tqdm(range(epochs)):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            steps += 1\n",
    "\n",
    "            inputs = inputs.float()\n",
    "            inputs, labels = inputs.to(device),labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # print(inputs.shape)\n",
    "            # print(model.forward(inputs).shape)\n",
    "            output,_ = model.forward(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                model.eval()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    valid_loss, accuracy = validation(model, valid_loader, criterion)\n",
    "\n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.6f}.. \".format(train_loss/print_every),\n",
    "                      \"Val Loss: {:.6f}.. \".format(valid_loss/len(valid_loader)),\n",
    "                      \"Val Accuracy: {:.2f}%\".format(accuracy/len(valid_loader)*100))\n",
    "\n",
    "                # save model if validation loss has decreased\n",
    "                if valid_loss <= valid_loss_min:\n",
    "                    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                    valid_loss_min,\n",
    "                    valid_loss))\n",
    "                    torch.save(model.state_dict(), savepath+ 'malstm_msn_cv_'+str(cv)+'_cond_'+str(cond)+'_esb_'+str(esbnum)+'.pt')\n",
    "                    valid_loss_min = valid_loss\n",
    "\n",
    "                train_loss = 0\n",
    "\n",
    "                model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1376c6-4e46-43aa-8930-24726b1cee99",
   "metadata": {},
   "source": [
    "### ensemble1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb9f4841-b870-422b-8de5-e3a1c3587dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble1 = MLSTMfcn_MSN(num_classes=5, \n",
    "                           num_features=3,\n",
    "                           num_lstm_out=num_lstm_out).to(device)\n",
    "ensemble2 = MLSTMfcn_MSN(num_classes=5, \n",
    "                           num_features=3,\n",
    "                           num_lstm_out=num_lstm_out).to(device)\n",
    "ensemble3 = MLSTMfcn_MSN(num_classes=5, \n",
    "                           num_features=3,\n",
    "                           num_lstm_out=num_lstm_out).to(device)\n",
    "ensemble4 = MLSTMfcn_MSN(num_classes=5, \n",
    "                           num_features=3,\n",
    "                           num_lstm_out=num_lstm_out).to(device)\n",
    "ensemble5 = MLSTMfcn_MSN(num_classes=5, \n",
    "                           num_features=3,\n",
    "                           num_lstm_out=num_lstm_out).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b985c1a-938d-41c8-8b4f-d7e5203ef3d4",
   "metadata": {},
   "source": [
    "### 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "851c5ad0-c4ec-4455-b87d-cce03b9e834c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5a85921-e9d1-4661-837f-c21691706c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader,valid_loader,test_loader=loaders(cross_val_train_set,cross_val_train_label,cross_val_test_set,cross_val_test_label,1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94ded44a-63e9-4450-b348-fecd3ca0ad30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(classifier1,classifier2,classifier3,classifier4,classifier5, dataloader):\n",
    "    # setup the network\n",
    "    predlist=[]\n",
    "    real=[]    \n",
    "\n",
    "    classifier1.eval()\n",
    "    classifier2.eval()\n",
    "    classifier3.eval()\n",
    "    classifier4.eval()\n",
    "    classifier5.eval()\n",
    "    correct = 0.0\n",
    "    \n",
    "    max_tr_score = 0\n",
    "    max_val_score = 0\n",
    "    for batch_idx, (data) in enumerate(dataloader):\n",
    "    \n",
    "        signal1,label = data\n",
    "        signal1,label = Variable(signal1.cuda()),Variable(label.cuda().long())\n",
    "        \n",
    "        \n",
    "        out1,_ = classifier1(signal1)\n",
    "        out2,_ = classifier2(signal1) \n",
    "        out3,_ = classifier3(signal1)\n",
    "        out4,_ = classifier4(signal1)\n",
    "        out5,_ = classifier5(signal1)\n",
    "\n",
    "        out1 = torch.exp(out1)\n",
    "        out2 = torch.exp(out2) \n",
    "        out3 = torch.exp(out3)\n",
    "        out4 = torch.exp(out4)\n",
    "        out5 = torch.exp(out5)        \n",
    "        \n",
    "        \n",
    "        out=(out1+out2+out3+out4+out5)/5\n",
    "        \n",
    "        pred = out.data.max(1, keepdim= True)[1]\n",
    "        predlist.append(pred.cpu().detach().numpy().squeeze())\n",
    "        real.append(label)        \n",
    "        correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        # predlist.append(pred)\n",
    "    print('\\nAccuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        correct, len(dataloader.dataset), 100. * float(correct) / len(dataloader.dataset)))\n",
    "    acc=100. * float(correct) / len(dataloader.dataset)\n",
    "    return acc,predlist,real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "672b698a-89f3-4d62-8069-03487bd86027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_origin(classifier1,classifier2,classifier3,classifier4,classifier5, dataloader):\n",
    "    # setup the network\n",
    "    predlist=[]\n",
    "    real=[]    \n",
    "\n",
    "    classifier1.eval()\n",
    "    classifier2.eval()\n",
    "    classifier3.eval()\n",
    "    classifier4.eval()\n",
    "    classifier5.eval()\n",
    "    correct = 0.0\n",
    "    \n",
    "    max_tr_score = 0\n",
    "    max_val_score = 0\n",
    "    for batch_idx, (data) in enumerate(dataloader):\n",
    "    \n",
    "        signal1,label = data\n",
    "        signal1,label = Variable(signal1.cuda()),Variable(label.cuda().long())\n",
    "        \n",
    "        \n",
    "        out1,_ = classifier1(signal1)\n",
    "        out2,_ = classifier2(signal1) \n",
    "        out3,_ = classifier3(signal1)\n",
    "        out4,_ = classifier4(signal1)\n",
    "        out5,_ = classifier5(signal1)\n",
    "\n",
    "        \n",
    "        \n",
    "        out=(out1+out2+out3+out4+out5)/5\n",
    "        \n",
    "        pred = out.data.max(1, keepdim= True)[1]\n",
    "        predlist.append(pred.cpu().detach().numpy().squeeze())\n",
    "        real.append(label)        \n",
    "        correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "        \n",
    "\n",
    "        # predlist.append(pred)\n",
    "    print('\\nAccuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        correct, len(dataloader.dataset), 100. * float(correct) / len(dataloader.dataset)))\n",
    "    acc=100. * float(correct) / len(dataloader.dataset)\n",
    "    return acc,predlist,real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bf2e1b5-4b7d-4e4b-9d3b-fd6a6138104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardvoting(classifier1,classifier2,classifier3,classifier4,classifier5, dataloader):\n",
    "    # setup the network\n",
    "    predlist=[]\n",
    "    real=[]    \n",
    "\n",
    "    classifier1.eval()\n",
    "    classifier2.eval()\n",
    "    classifier3.eval()\n",
    "    classifier4.eval()\n",
    "    classifier5.eval()\n",
    "    correct = 0.0\n",
    "    \n",
    "    max_tr_score = 0\n",
    "    max_val_score = 0\n",
    "    for batch_idx, (data) in enumerate(dataloader):\n",
    "    \n",
    "        signal1,label = data\n",
    "        signal1,label = Variable(signal1.cuda()),Variable(label.cuda().long())\n",
    "        \n",
    "        \n",
    "        out1,_ = classifier1(signal1)\n",
    "        out2,_ = classifier2(signal1) \n",
    "        out3,_ = classifier3(signal1)\n",
    "        out4,_ = classifier4(signal1)\n",
    "        out5,_ = classifier5(signal1)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        pred1 = out1.data.max(1, keepdim= True)[1].cpu().detach().numpy().squeeze()\n",
    "        pred2 = out2.data.max(1, keepdim= True)[1].cpu().detach().numpy().squeeze()\n",
    "        pred3 = out3.data.max(1, keepdim= True)[1].cpu().detach().numpy().squeeze()\n",
    "        pred4 = out4.data.max(1, keepdim= True)[1].cpu().detach().numpy().squeeze()\n",
    "        pred5 = out5.data.max(1, keepdim= True)[1].cpu().detach().numpy().squeeze()\n",
    "        \n",
    "        preds=[pred1,pred2,pred3,pred4,pred5]\n",
    "        pred= torch.tensor(max(preds, key=preds.count))\n",
    "\n",
    "\n",
    "        predlist.append(pred)\n",
    "        real.append(label)        \n",
    "\n",
    "        correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "        \n",
    "\n",
    "        # predlist.append(pred)\n",
    "    print('\\nAccuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        correct, len(dataloader.dataset), 100. * float(correct) / len(dataloader.dataset)))\n",
    "    acc=100. * float(correct) / len(dataloader.dataset)\n",
    "    return acc,predlist,real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb73996f-3e2d-48fe-9056-c46bad521862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 9959.0/10000 (99.5900%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc,predlist,real= hardvoting(ensemble1,ensemble2,ensemble3,ensemble4,ensemble5, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23e11d80-304b-414f-ae67-c7e551b7cc89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble1.load_state_dict(torch.load(savepath+ 'malstm_msn_cv_'+str(cv)+'_cond_'+str(cond)+'_esb_'+str(1)+'.pt'))\n",
    "ensemble2.load_state_dict(torch.load(savepath+ 'malstm_msn_cv_'+str(cv)+'_cond_'+str(cond)+'_esb_'+str(2)+'.pt'))\n",
    "ensemble3.load_state_dict(torch.load(savepath+ 'malstm_msn_cv_'+str(cv)+'_cond_'+str(cond)+'_esb_'+str(3)+'.pt'))\n",
    "ensemble4.load_state_dict(torch.load(savepath+ 'malstm_msn_cv_'+str(cv)+'_cond_'+str(cond)+'_esb_'+str(4)+'.pt'))\n",
    "ensemble5.load_state_dict(torch.load(savepath+ 'malstm_msn_cv_'+str(cv)+'_cond_'+str(cond)+'_esb_'+str(0)+'.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1674c41-ffbc-424f-8ec8-b709d48e1e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 9962.0/10000 (99.6200%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc,predlist,real= test_origin(ensemble1,ensemble2,ensemble3,ensemble4,ensemble5, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "992c491d-5d23-43c3-80d3-defedfbb2521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 9960.0/10000 (99.6000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc,predlist,real= test(ensemble1,ensemble2,ensemble3,ensemble4,ensemble5, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7e8b1-25f8-45c2-aa5f-f985402a27d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
